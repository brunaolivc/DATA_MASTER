{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, roc_auc_score, f1_score, log_loss\n",
    "from xgboost import XGBClassifier, DMatrix, train, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"train.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76015</td>\n",
       "      <td>151829</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60926.490000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76016</td>\n",
       "      <td>151830</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118634.520000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76017</td>\n",
       "      <td>151835</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74028.150000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76018</td>\n",
       "      <td>151836</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84278.160000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76019</td>\n",
       "      <td>151838</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76020 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0           1     2     23                 0.0                      0.0   \n",
       "1           3     2     34                 0.0                      0.0   \n",
       "2           4     2     23                 0.0                      0.0   \n",
       "3           8     2     37                 0.0                    195.0   \n",
       "4          10     2     39                 0.0                      0.0   \n",
       "...       ...   ...    ...                 ...                      ...   \n",
       "76015  151829     2     48                 0.0                      0.0   \n",
       "76016  151830     2     39                 0.0                      0.0   \n",
       "76017  151835     2     23                 0.0                      0.0   \n",
       "76018  151836     2     25                 0.0                      0.0   \n",
       "76019  151838     2     46                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                        195.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "76015                      0.0                      0.0   \n",
       "76016                      0.0                      0.0   \n",
       "76017                      0.0                      0.0   \n",
       "76018                      0.0                      0.0   \n",
       "76019                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "76015                      0.0                      0.0   \n",
       "76016                      0.0                      0.0   \n",
       "76017                      0.0                      0.0   \n",
       "76018                      0.0                      0.0   \n",
       "76019                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  ...  saldo_medio_var33_hace2  \\\n",
       "0                          0.0  ...                      0.0   \n",
       "1                          0.0  ...                      0.0   \n",
       "2                          0.0  ...                      0.0   \n",
       "3                          0.0  ...                      0.0   \n",
       "4                          0.0  ...                      0.0   \n",
       "...                        ...  ...                      ...   \n",
       "76015                      0.0  ...                      0.0   \n",
       "76016                      0.0  ...                      0.0   \n",
       "76017                      0.0  ...                      0.0   \n",
       "76018                      0.0  ...                      0.0   \n",
       "76019                      0.0  ...                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "76015                      0.0                     0.0   \n",
       "76016                      0.0                     0.0   \n",
       "76017                      0.0                     0.0   \n",
       "76018                      0.0                     0.0   \n",
       "76019                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "76015                     0.0                      0.0   \n",
       "76016                     0.0                      0.0   \n",
       "76017                     0.0                      0.0   \n",
       "76018                     0.0                      0.0   \n",
       "76019                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "76015                      0.0                     0.0   \n",
       "76016                      0.0                     0.0   \n",
       "76017                      0.0                     0.0   \n",
       "76018                      0.0                     0.0   \n",
       "76019                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                         0.0   39205.170000       0  \n",
       "1                         0.0   49278.030000       0  \n",
       "2                         0.0   67333.770000       0  \n",
       "3                         0.0   64007.970000       0  \n",
       "4                         0.0  117310.979016       0  \n",
       "...                       ...            ...     ...  \n",
       "76015                     0.0   60926.490000       0  \n",
       "76016                     0.0  118634.520000       0  \n",
       "76017                     0.0   74028.150000       0  \n",
       "76018                     0.0   84278.160000       0  \n",
       "76019                     0.0  117310.979016       0  \n",
       "\n",
       "[76020 rows x 371 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "#Verificando os tipos de dados existentes na base\n",
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando se ha valores missing padrao (None, NaN) na base como um todo \n",
    "dados.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_nodup = dados.drop_duplicates()\n",
    "dados_nodup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 371), (22806, 371))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separa a base em 70% treino e 30% teste, estratificada pela TARGET, uma vez que ela nao tem uma proporcao equilibrada na base\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(dados_nodup, test_size=0.3,stratify=dados_nodup['TARGET'],random_state=42)\n",
    "train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>51108</td>\n",
       "      <td>96.042395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2106</td>\n",
       "      <td>3.957605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET  Percentage\n",
       "0   51108   96.042395\n",
       "1    2106    3.957605"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(train_set.TARGET.value_counts())\n",
    "df['Percentage'] = 100*df['TARGET']/train_set.shape[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21904</td>\n",
       "      <td>96.0449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>902</td>\n",
       "      <td>3.9551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET  Percentage\n",
       "0   21904     96.0449\n",
       "1     902      3.9551"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test_set.TARGET.value_counts())\n",
    "df['Percentage'] = 100*df['TARGET']/test_set.shape[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 369)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOVER COLUNAS IGUAIS\n",
    "features = train_set.drop(['TARGET','ID'],axis=1)\n",
    "corr_matrix = features.corr()\n",
    "corr_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#como a matriz de correlacao se repete na diagonal superior e inferior, escolhi uma delas \n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_var18', 'ind_var26', 'ind_var25', 'ind_var29_0', 'ind_var29', 'ind_var32', 'ind_var37', 'ind_var39', 'num_var18', 'num_var26', 'num_var25', 'num_var29_0', 'num_var29', 'num_var32', 'num_var37', 'num_var39', 'saldo_var29', 'delta_num_aport_var33_1y3', 'delta_num_reemb_var13_1y3', 'delta_num_reemb_var17_1y3', 'delta_num_trasp_var17_in_1y3', 'delta_num_trasp_var17_out_1y3', 'delta_num_trasp_var33_in_1y3', 'delta_num_trasp_var33_out_1y3', 'delta_num_venta_var44_1y3']\n"
     ]
    }
   ],
   "source": [
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] == 1)] \n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>61553</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>48.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>209.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175887.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6865</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111297.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40817</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80805.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71630</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124585.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 344 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "61553     2     38                48.0                    102.0   \n",
       "6865      2     51                 0.0                      0.0   \n",
       "847       2     23                 0.0                      0.0   \n",
       "40817     2     23                 0.0                      0.0   \n",
       "71630     2     23                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "61553                    209.7                      0.0   \n",
       "6865                       0.0                      0.0   \n",
       "847                        0.0                      0.0   \n",
       "40817                      0.0                      0.0   \n",
       "71630                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "61553                      0.0                      0.0   \n",
       "6865                       0.0                      0.0   \n",
       "847                        0.0                      0.0   \n",
       "40817                      0.0                      0.0   \n",
       "71630                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "61553                      0.0                0.0  ...   \n",
       "6865                       0.0                0.0  ...   \n",
       "847                        0.0                0.0  ...   \n",
       "40817                      0.0                0.0  ...   \n",
       "71630                      0.0                0.0  ...   \n",
       "\n",
       "       saldo_medio_var29_ult3  saldo_medio_var33_hace2  \\\n",
       "61553                     0.0                      0.0   \n",
       "6865                      0.0                      0.0   \n",
       "847                       0.0                      0.0   \n",
       "40817                     0.0                      0.0   \n",
       "71630                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "61553                      0.0                     0.0   \n",
       "6865                       0.0                     0.0   \n",
       "847                        0.0                     0.0   \n",
       "40817                      0.0                     0.0   \n",
       "71630                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "61553                     0.0                      0.0   \n",
       "6865                      0.0                      0.0   \n",
       "847                       0.0                      0.0   \n",
       "40817                     0.0                      0.0   \n",
       "71630                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "61553                      0.0                     0.0   \n",
       "6865                       0.0                     0.0   \n",
       "847                        0.0                     0.0   \n",
       "40817                      0.0                     0.0   \n",
       "71630                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  \n",
       "61553                     0.0  175887.150000  \n",
       "6865                      0.0  111297.030000  \n",
       "847                       0.0  117310.979016  \n",
       "40817                     0.0   80805.900000  \n",
       "71630                     0.0  124585.620000  \n",
       "\n",
       "[5 rows x 344 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_1 = features.drop(to_drop, axis=1)\n",
    "features_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_var2_0', 'ind_var2', 'ind_var13_medio_0', 'ind_var13_medio', 'ind_var27_0', 'ind_var28_0', 'ind_var28', 'ind_var27', 'ind_var34_0', 'ind_var34', 'ind_var41', 'ind_var46_0', 'ind_var46', 'num_var13_medio_0', 'num_var13_medio', 'num_var27_0', 'num_var28_0', 'num_var28', 'num_var27', 'num_var34_0', 'num_var34', 'num_var41', 'num_var46_0', 'num_var46', 'saldo_var13_medio', 'saldo_var28', 'saldo_var27', 'saldo_var34', 'saldo_var41', 'saldo_var46', 'delta_imp_amort_var34_1y3', 'delta_imp_reemb_var33_1y3', 'delta_num_reemb_var33_1y3', 'imp_amort_var18_hace3', 'imp_amort_var34_hace3', 'imp_amort_var34_ult1', 'imp_reemb_var13_hace3', 'imp_reemb_var17_hace3', 'imp_reemb_var33_hace3', 'imp_reemb_var33_ult1', 'imp_trasp_var17_out_hace3', 'imp_trasp_var33_out_hace3', 'num_var2_0_ult1', 'num_var2_ult1', 'num_meses_var13_medio_ult3', 'num_reemb_var13_hace3', 'num_reemb_var17_hace3', 'num_reemb_var33_hace3', 'num_reemb_var33_ult1', 'num_trasp_var17_out_hace3', 'num_trasp_var33_out_hace3', 'saldo_var2_ult1', 'saldo_medio_var13_medio_hace2', 'saldo_medio_var13_medio_hace3', 'saldo_medio_var13_medio_ult1', 'saldo_medio_var13_medio_ult3', 'saldo_medio_var29_hace3']\n"
     ]
    }
   ],
   "source": [
    "#REMOVER VARIAVEIS CONSTANTES, OU SEJA, COM VARIANCIA ZERO\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0)\n",
    "sel.fit(features_1)  # fit encontra variaveis com variancia zero\n",
    "#get_support() eh um vetor que indica quais variaveis NAO tem variancia zero\n",
    "to_drop_2 = [column for column in features_1.columns if column not in features_1.columns[sel.get_support()]] \n",
    "print(to_drop_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "print(len(to_drop_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>61553</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>48.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>209.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175887.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6865</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111297.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40817</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80805.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71630</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124585.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "61553     2     38                48.0                    102.0   \n",
       "6865      2     51                 0.0                      0.0   \n",
       "847       2     23                 0.0                      0.0   \n",
       "40817     2     23                 0.0                      0.0   \n",
       "71630     2     23                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "61553                    209.7                      0.0   \n",
       "6865                       0.0                      0.0   \n",
       "847                        0.0                      0.0   \n",
       "40817                      0.0                      0.0   \n",
       "71630                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "61553                      0.0                      0.0   \n",
       "6865                       0.0                      0.0   \n",
       "847                        0.0                      0.0   \n",
       "40817                      0.0                      0.0   \n",
       "71630                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "61553                      0.0                0.0  ...   \n",
       "6865                       0.0                0.0  ...   \n",
       "847                        0.0                0.0  ...   \n",
       "40817                      0.0                0.0  ...   \n",
       "71630                      0.0                0.0  ...   \n",
       "\n",
       "       saldo_medio_var29_ult3  saldo_medio_var33_hace2  \\\n",
       "61553                     0.0                      0.0   \n",
       "6865                      0.0                      0.0   \n",
       "847                       0.0                      0.0   \n",
       "40817                     0.0                      0.0   \n",
       "71630                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "61553                      0.0                     0.0   \n",
       "6865                       0.0                     0.0   \n",
       "847                        0.0                     0.0   \n",
       "40817                      0.0                     0.0   \n",
       "71630                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "61553                     0.0                      0.0   \n",
       "6865                      0.0                      0.0   \n",
       "847                       0.0                      0.0   \n",
       "40817                     0.0                      0.0   \n",
       "71630                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "61553                      0.0                     0.0   \n",
       "6865                       0.0                     0.0   \n",
       "847                        0.0                     0.0   \n",
       "40817                      0.0                     0.0   \n",
       "71630                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  \n",
       "61553                     0.0  175887.150000  \n",
       "6865                      0.0  111297.030000  \n",
       "847                       0.0  117310.979016  \n",
       "40817                     0.0   80805.900000  \n",
       "71630                     0.0  124585.620000  \n",
       "\n",
       "[5 rows x 287 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_2= features_1.drop(to_drop_2, axis=1)\n",
    "features_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53214, 287)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full</th>\n",
       "      <th>abv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>var3</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>var15</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>imp_ent_var16_ult1</td>\n",
       "      <td>imp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>imp_op_var39_comer_ult1</td>\n",
       "      <td>imp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>imp_op_var39_comer_ult3</td>\n",
       "      <td>imp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>saldo_medio_var44_hace2</td>\n",
       "      <td>sal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>saldo_medio_var44_hace3</td>\n",
       "      <td>sal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>saldo_medio_var44_ult1</td>\n",
       "      <td>sal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>saldo_medio_var44_ult3</td>\n",
       "      <td>sal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>var38</td>\n",
       "      <td>var</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        full  abv\n",
       "0                       var3  var\n",
       "1                      var15  var\n",
       "2         imp_ent_var16_ult1  imp\n",
       "3    imp_op_var39_comer_ult1  imp\n",
       "4    imp_op_var39_comer_ult3  imp\n",
       "..                       ...  ...\n",
       "282  saldo_medio_var44_hace2  sal\n",
       "283  saldo_medio_var44_hace3  sal\n",
       "284   saldo_medio_var44_ult1  sal\n",
       "285   saldo_medio_var44_ult3  sal\n",
       "286                    var38  var\n",
       "\n",
       "[287 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'full': features_2.columns}\n",
    "colunas = pd.DataFrame(dict)\n",
    "\n",
    "colunas['abv'] = colunas['full'].str.slice(0,3)\n",
    "colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abv</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>del</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>imp</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ind</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sal</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>var</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     full\n",
       "abv      \n",
       "del    15\n",
       "imp    40\n",
       "ind    54\n",
       "num   115\n",
       "sal    58\n",
       "var     5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunas.groupby('abv').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7f2c871d10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARnElEQVR4nO3df7DldV3H8edLNpPYAg254cK0WJumboRcGZOx7kozEVhQQWI7thrNToVkmZOYTfgPhZNkRandxKBpx5XIWhTGJPJqToKySC4ICMECCxsrA6xdIBV598f57nhdLuze8+Me7uc+HzM793x/nc/7vefu637O937Pd1NVSJLa8qxxFyBJGj7DXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQfsM9yQfSrIryY1z1v1pkluSfCnJPyc5ZM62dyS5PcmtSX5mVIVLkp7a/szcLwZO3GvdVcDLqurHgK8A7wBI8hLgDOCl3THvS3LA0KqVJO2XFfvaoao+k2T1Xus+OWfxGuC07vEpwOaq+jpwZ5LbgeOAzz3dGIceemitXr366XZ5So888ggHHXRQX8cuVfa8PNjz8jBIz1u3bn2gqp4/37Z9hvt++DXgI93jVfTCfo8d3bqntXr1aq677rq+Bp+ZmWFqaqqvY5cqe14e7Hl5GKTnJHc91baBwj3JO4HHgU17Vs2z27z3N0iyEdgIMDExwczMTF81zM7O9n3sUmXPy4M9Lw+j6rnvcE+yAXgtcEJ9+wY1O4Aj5+x2BHDffMdX1TQwDTA5OVn9/uTyJ/3yYM/Lgz0PT1+XQiY5EXg78PNV9eicTZcDZyT57iRHAWuAzw9epiRpIfY5c0/yYWAKODTJDuBcelfHfDdwVRKAa6rqN6rqpiSXAl+md7rmrKr61qiKlyTNb3+ulnn9PKsvepr9zwPOG6QoSdJg/ISqJDXIcJekBhnuktQgw12SGjSMT6hKGoFt9+7mjedcsejjbj//5EUfU8PnzF2SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDVon+Ge5ENJdiW5cc665yW5Kslt3dfnduuT5C+T3J7kS0lePsriJUnz25+Z+8XAiXutOwe4uqrWAFd3ywA/C6zp/mwE3j+cMiVJC7HPcK+qzwAP7rX6FOCS7vElwKlz1v999VwDHJLk8GEVK0naP/2ec5+oqp0A3dfDuvWrgHvm7LejWydJWkQrhvx8mWddzbtjspHeqRsmJiaYmZnpa8DZ2dm+j12q7Hl5mDgQfm/t44s+7jj/npfj6zyqnvsN9/uTHF5VO7vTLru69TuAI+fsdwRw33xPUFXTwDTA5ORkTU1N9VXIzMwM/R67VNnz8nDhpi1csG3Y8699275+atHH3GM5vs6j6rnf0zKXAxu6xxuALXPW/2p31cwrgd17Tt9IkhbPPqcFST4MTAGHJtkBnAucD1ya5EzgbuD0bvcrgZOA24FHgTeNoGZJ0j7sM9yr6vVPsemEefYt4KxBi5IkDcZPqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDRoo3JP8bpKbktyY5MNJnpPkqCTXJrktyUeSPHtYxUqS9k/f4Z5kFfDbwGRVvQw4ADgDeDfw3qpaAzwEnDmMQiVJ+2/Q0zIrgAOTrAC+B9gJvAa4rNt+CXDqgGNIkhao73CvqnuB9wB30wv13cBW4OGqerzbbQewatAiJUkLk6rq78DkucA/Aa8DHgb+sVs+t6p+uNvnSODKqlo7z/EbgY0AExMTx27evLmvOmZnZ1m5cmVfxy5V9rw87HpwN/c/tvjjrl118OIP2lmOr/MgPa9bt25rVU3Ot23FADX9NHBnVX0VIMlHgVcBhyRZ0c3ejwDum+/gqpoGpgEmJydramqqryJmZmbo99ilyp6Xhws3beGCbYP8E+3P9vVTiz7mHsvxdR5Vz4Occ78beGWS70kS4ATgy8CngNO6fTYAWwYrUZK0UIOcc7+W3i9Orwe2dc81DbwdeGuS24HvBy4aQp2SpAUY6D1fVZ0LnLvX6juA4wZ5XknSYPyEqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoIHCPckhSS5LckuSm5P8RJLnJbkqyW3d1+cOq1hJ0v4ZdOb+F8AnqurFwNHAzcA5wNVVtQa4uluWJC2ivsM9yfcBPwlcBFBV36iqh4FTgEu63S4BTh20SEnSwgwyc38h8FXg75J8MckHkxwETFTVToDu62FDqFOStACpqv4OTCaBa4Djq+raJH8BfA04u6oOmbPfQ1X1pPPuSTYCGwEmJiaO3bx5c191zM7OsnLlyr6OXarseXnY9eBu7n9s8cddu+rgxR+0sxxf50F6Xrdu3daqmpxv24oBatoB7Kiqa7vly+idX78/yeFVtTPJ4cCu+Q6uqmlgGmBycrKmpqb6KmJmZoZ+j12q7Hl5uHDTFi7YNsg/0f5sXz+16GPusRxf51H13Pdpmar6H+CeJC/qVp0AfBm4HNjQrdsAbBmoQknSgg06LTgb2JTk2cAdwJvo/cC4NMmZwN3A6QOOIWmZ2Hbvbt54zhWLPu72809e9DFHbaBwr6obgPnO95wwyPNKkgbjJ1QlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgxb/429SH8Z1/TO0eQ202ufMXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDRo43JMckOSLST7eLR+V5NoktyX5SJJnD16mJGkhhjFzfwtw85zldwPvrao1wEPAmUMYQ5K0AAOFe5IjgJOBD3bLAV4DXNbtcglw6iBjSJIWbtCZ+58Dvw880S1/P/BwVT3eLe8AVg04hiRpgVJV/R2YvBY4qap+K8kU8DbgTcDnquqHu32OBK6sqrXzHL8R2AgwMTFx7ObNm/uqY3Z2lpUrV/Z17FK168Hd3P/YeMZeu+rgsYxrz4tnXP3C8ux5kAxbt27d1qqanG/bigFqOh74+SQnAc8Bvo/eTP6QJCu62fsRwH3zHVxV08A0wOTkZE1NTfVVxMzMDP0eu1RduGkLF2wb5KXr3/b1U2MZ154Xz7j6heXZ86gyrO/TMlX1jqo6oqpWA2cA/15V64FPAad1u20AtgxcpSRpQUZxnfvbgbcmuZ3eOfiLRjCGJOlpDOX9T1XNADPd4zuA44bxvJKk/vgJVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQX2He5Ijk3wqyc1Jbkrylm7985JcleS27utzh1euJGl/DDJzfxz4var6UeCVwFlJXgKcA1xdVWuAq7tlSdIi6jvcq2pnVV3fPf5f4GZgFXAKcEm32yXAqYMWKUlamKGcc0+yGjgGuBaYqKqd0PsBABw2jDEkSfsvVTXYEyQrgU8D51XVR5M8XFWHzNn+UFU96bx7ko3ARoCJiYljN2/e3Nf4s7OzrFy5sr/il6hdD+7m/sfGM/baVQePZVx7Xjzj6heWZ8+DZNi6deu2VtXkfNtWDFJUku8C/gnYVFUf7Vbfn+TwqtqZ5HBg13zHVtU0MA0wOTlZU1NTfdUwMzNDv8cuVRdu2sIF2wZ66fq2ff3UWMa158Uzrn5hefY8qgwb5GqZABcBN1fVn83ZdDmwoXu8AdjSf3mSpH4M8iPyeOANwLYkN3Tr/gA4H7g0yZnA3cDpg5UoSVqovsO9qj4L5Ck2n9Dv80qSBucnVCWpQYa7JDXIcJekBhnuktSg8Vw4LEnPIKvPuWJsY1984kEjeV5n7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgJf8/MW27dzdvHNP/orL9/JPHMq4k7Yszd0lqkOEuSQ0y3CWpQYa7JDVoZOGe5MQktya5Pck5oxpHkvRkIwn3JAcAfw38LPAS4PVJXjKKsSRJTzaqmftxwO1VdUdVfQPYDJwyorEkSXsZVbivAu6Zs7yjWydJWgSpquE/aXI68DNV9evd8huA46rq7Dn7bAQ2dosvAm7tc7hDgQcGKHcpsuflwZ6Xh0F6/sGqev58G0b1CdUdwJFzlo8A7pu7Q1VNA9ODDpTkuqqaHPR5lhJ7Xh7seXkYVc+jOi3zBWBNkqOSPBs4A7h8RGNJkvYykpl7VT2e5M3AvwIHAB+qqptGMZYk6clGduOwqroSuHJUzz/HwKd2liB7Xh7seXkYSc8j+YWqJGm8vP2AJDXIcH8GSvKf465hHBbad5KpJB8fVT0avyQXJzlt3HUMW5J3JXlbv9v3R9Phnp4l12NVvWrcNYzDcu1bGoUlEXxJ3p3kt+YsvyvJuUmuTnJ9km1JTum2rU5yc5L3AdfzndfbLwlJZruvU0k+neTSJF9Jcn6S9Uk+3/X8Q91+Fyf5QJL/6PZ77Xg76M9efc8kuSzJLUk2JUm37cRu3WeBXxxrwX2a8z36t0luSvLJJAd2PU92+xyaZHv3+I1J/iXJx5LcmeTNSd6a5ItJrknyvLE2tEBJDkpyRZL/SnJjktcl+aMkX+iWp/e83i1J8s7uZor/Ru+DmyT5oSSfSLK1+/f74mGNtyTCnd69aV43Z/mXgb8DfqGqXg6sAy6Y8w3xIuDvq+qYqrprcUsduqOBtwBrgTcAP1JVxwEfBM6es99q4KeAk4EPJHnOItc5bMcAv0PvxnMvBI7vevpb4OeAVwM/ML7yBrYG+OuqeinwMPBL+9j/ZcCv0Ltv03nAo1V1DPA54FdHWegInAjcV1VHV9XLgE8Af1VVr+iWDwSW5ATlqSQ5lt7nfY6hNyl5RbdpGji7qo4F3ga8b1hjLolwr6ovAocleUGSo4GHgJ3AHyf5EvBv9O5dM9EdcldVXTOeaofuC1W1s6q+Dvw38Mlu/TZ6gb7HpVX1RFXdBtwBDG0GMCafr6odVfUEcAO9Xl8M3FlVt1XvMq9/GGeBA7qzqm7oHm/lO1/L+Xyqqv63qr4K7AY+1q3f+/tgKdgG/HT3jvzVVbUbWJfk2iTbgNcALx1viUP3auCfq+rRqvoavQ91Pgd4FfCPSW4A/gY4fFgDLqX/IPsy4DR6s7XNwHrg+cCxVfXN7i3sntnqI2OpcDS+PufxE3OWn+A7X7+9r2ld6te4zu37W3y716Xe1x5793cg8DjfnnDt/c5rf78PnvGq6ivdTPYk4E+SfBI4C5isqnuSvIsn99+Cvb93nwU8XFU/PorBlsTMvbOZ3tua0+gF/cHAri7Y1wE/OM7ingFOT/Ks7jz8C+n/RmzPZLcAR+35XQPw+nEWMwLbgWO7x81dIbJHkhfQO630D8B7gJd3mx5IspI2e/8M8Avd71a+l96pxUeBO9O70eKeC0COHtaAS+YnflXd1P2l3FtVO5NsAj6W5Dp6b9tvGW+FY3cr8Gl6p6Z+o6r+b8z1DF1V/V96dxO9IskDwGfpnYtuxXuAS9O7i+q/j7uYEVoL/GmSJ4BvAr8JnErvdM12evemakpVXZ/kI/Sy6i7gP7pN64H3J/lD4LvoTWL/axhj+gnVBiS5GPh4VV027lokPTMspdMykqT95MxdkhrkzF2SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ16P8BBXAjmoZ/kUoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colunas.abv.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       var3\n",
       "1      var15\n",
       "146    var36\n",
       "193    var21\n",
       "286    var38\n",
       "Name: full, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunas[colunas['abv'] == 'var']['full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Binarias 80\n",
      "#Ate 10 categorias 78\n",
      "#Continuas 129\n"
     ]
    }
   ],
   "source": [
    "#TENTAR DETERMINAR SE AS VARIAVEIS SAO BINARIAS, CATEGORICAS OU CONTINUAS\n",
    "\n",
    "#PRIMEIRO VERIFICOU-SE A QUANTIDADE DE DOMINIOS DE CADA VARIAVEL DA BASE E TENTOU-SE AGRUPAR POR QUANTIDADE DE DOMINIOS\n",
    "#BINARIAS: 2 DOMINIOS\n",
    "#CATEGORICAS ATE 10 DOMINIOS: DE 3 A 10 DOMINIOS OU VARS COM INICIO DO NOME DA VARIAVEL NUM (TODAS ELAS PARECEM TER\n",
    "# APENAS VALORES INTEIROS ATRAVES DO DESCRIBE), REMOVENDO VARIAVEIS COM VALORES NAO INTEIROS (ELAS SE TORNAM CONTINUAS)\n",
    "#CONTINUAS: FOI FEITO UM TRABALHO DE VERIFICAR QUAL ERA UMA QUANTIDADE MINIMA DE DOMINIOS NECESSARIOS PARA A VARIAVEL\n",
    "# DEIXAR DE SER CATEGORICA E SE TORNAR CONTINUA, INICIOU-SE O TESTE VERIFICANDO SE A QUANTIDADE DE DOMINIOS ERA MAIOR\n",
    "# QUE N/2 E FOI-SE DIMINUINDO E VERIFICANDO QUAIS VARIAVEIS ALI TINHAM NOMES PARECIDOS, ALEM DE VERIFICAR SE O DESCRIBE\n",
    "# MOSTRAVA VALORES QUEBRADOS OU VALORES INTEIROS.\n",
    "#  VARS COM INICIO DO NOME DA VARIAVEL SALDO, IMP OU DELTA (-1 A 1)\n",
    "\n",
    "\n",
    "#VETORES DE TESTE\n",
    "vars_bin = []\n",
    "vars_cat10 = []\n",
    "vars_cont = []\n",
    "\n",
    "vars_bin = [columns for columns in features_2.columns if len(features_2[columns].value_counts()) == 2]\n",
    "\n",
    "vars_cat10 = [columns for columns in features_2.columns \n",
    "              if columns not in vars_bin\n",
    "              and len(features_2[columns].value_counts()) <= 10\n",
    "              or columns in colunas[colunas['abv'] == 'var']['full']]\n",
    "#vars_cont = [columns for columns in features_2.columns if len(features_2[columns].value_counts()) > 10 and len(features_2[columns].value_counts()) > int((features_2.shape[0])/500)]\n",
    "vars_cont = [columns for columns in features_2.columns \n",
    "             if columns not in vars_bin \n",
    "             and columns not in vars_cat10]\n",
    "print('#Binarias',len(vars_bin))\n",
    "print('#Ate 10 categorias',len(vars_cat10))\n",
    "print('#Continuas',len(vars_cont))\n",
    "#APARENTEMENTE:\n",
    "#BINARIAS: com 2 categorias\n",
    "#CATEGORICAS: com 3 categorias\n",
    "#CONTINUAS: SALDO ou IMP ou DELTA (-1 A 1)\n",
    "#CATEGORICAS: NUM ou ate 10 categorias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "#VERIFICA SE AS VARIAVEIS CONSIDERADAS CATEGORICAS SAO INTEIROS NAO NEGATIVOS, CASO CONTRARIO, CHAMAR DE CONTINUAS\n",
    "\n",
    "var_cat_true = []\n",
    "\n",
    "var_cat_true = [columns for columns in features_2[vars_cat10].columns \n",
    "                if np.array_equal(features_2[columns], features_2[columns].astype(int))\n",
    "                and np.array_equal(features_2[columns], abs(features_2[columns]))]\n",
    "print(len(var_cat_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "vars_to_cont = []\n",
    "\n",
    "vars_to_cont = [columns for columns in features_2[vars_cat10].columns if columns not in var_cat_true]\n",
    "print(len(vars_to_cont))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Binarias 80\n",
      "#Ate 10 categorias 60\n",
      "#Continuas 147\n"
     ]
    }
   ],
   "source": [
    "vars_cont_2 = []\n",
    "vars_cat10_2 = []\n",
    "\n",
    "vars_cont_2 = [columns for columns in features_2.columns if columns in vars_cont or columns in vars_to_cont]\n",
    "vars_cat10_2 = [columns for columns in features_2[vars_cat10].columns if columns not in vars_to_cont]\n",
    "print('#Binarias',len(vars_bin))\n",
    "print('#Ate 10 categorias',len(vars_cat10_2))\n",
    "print('#Continuas',len(vars_cont_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_var1_0',\n",
       " 'num_var4',\n",
       " 'num_var5_0',\n",
       " 'num_var5',\n",
       " 'num_var8_0',\n",
       " 'num_var12_0',\n",
       " 'num_var12',\n",
       " 'num_var13_0',\n",
       " 'num_var13_corto_0',\n",
       " 'num_var13_corto',\n",
       " 'num_var13_largo_0',\n",
       " 'num_var13_largo',\n",
       " 'num_var13',\n",
       " 'num_var14_0',\n",
       " 'num_var14',\n",
       " 'num_var17',\n",
       " 'num_var24_0',\n",
       " 'num_var24',\n",
       " 'num_var26_0',\n",
       " 'num_var25_0',\n",
       " 'num_op_var40_hace3',\n",
       " 'num_var30_0',\n",
       " 'num_var30',\n",
       " 'num_var31',\n",
       " 'num_var32_0',\n",
       " 'num_var33_0',\n",
       " 'num_var33',\n",
       " 'num_var39_0',\n",
       " 'num_var40_0',\n",
       " 'num_var41_0',\n",
       " 'num_var42_0',\n",
       " 'num_var42',\n",
       " 'var36',\n",
       " 'imp_aport_var33_ult1',\n",
       " 'num_aport_var13_hace3',\n",
       " 'num_aport_var13_ult1',\n",
       " 'num_aport_var17_hace3',\n",
       " 'num_aport_var17_ult1',\n",
       " 'num_aport_var33_hace3',\n",
       " 'num_aport_var33_ult1',\n",
       " 'num_var7_recib_ult1',\n",
       " 'num_compra_var44_hace3',\n",
       " 'num_compra_var44_ult1',\n",
       " 'num_meses_var5_ult3',\n",
       " 'num_meses_var8_ult3',\n",
       " 'num_meses_var12_ult3',\n",
       " 'num_meses_var13_corto_ult3',\n",
       " 'num_meses_var13_largo_ult3',\n",
       " 'num_meses_var17_ult3',\n",
       " 'num_meses_var29_ult3',\n",
       " 'num_meses_var33_ult3',\n",
       " 'num_meses_var39_vig_ult3',\n",
       " 'num_meses_var44_ult3',\n",
       " 'num_op_var40_efect_ult1',\n",
       " 'num_op_var40_efect_ult3',\n",
       " 'num_reemb_var17_ult1',\n",
       " 'num_sal_var16_ult1',\n",
       " 'num_trasp_var17_in_hace3',\n",
       " 'num_trasp_var33_in_ult1',\n",
       " 'num_venta_var44_ult1']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_cat10_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chi2</th>\n",
       "      <th>p-Value</th>\n",
       "      <th>associacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>num_var1_0</td>\n",
       "      <td>2.056941</td>\n",
       "      <td>1.515141e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var4</td>\n",
       "      <td>245.491116</td>\n",
       "      <td>2.497193e-55</td>\n",
       "      <td>2.497193e-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var5_0</td>\n",
       "      <td>7.597927</td>\n",
       "      <td>5.843544e-03</td>\n",
       "      <td>5.843544e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var5</td>\n",
       "      <td>987.652698</td>\n",
       "      <td>8.672433e-217</td>\n",
       "      <td>8.672433e-217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var8_0</td>\n",
       "      <td>375.266455</td>\n",
       "      <td>1.335196e-83</td>\n",
       "      <td>1.335196e-83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var12_0</td>\n",
       "      <td>85.862875</td>\n",
       "      <td>1.928557e-20</td>\n",
       "      <td>1.928557e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var12</td>\n",
       "      <td>156.720950</td>\n",
       "      <td>5.890152e-36</td>\n",
       "      <td>5.890152e-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var13_0</td>\n",
       "      <td>240.497758</td>\n",
       "      <td>3.063180e-54</td>\n",
       "      <td>3.063180e-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var13_corto_0</td>\n",
       "      <td>168.619793</td>\n",
       "      <td>1.481237e-38</td>\n",
       "      <td>1.481237e-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var13_corto</td>\n",
       "      <td>171.138710</td>\n",
       "      <td>4.173166e-39</td>\n",
       "      <td>4.173166e-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var13_largo_0</td>\n",
       "      <td>73.507177</td>\n",
       "      <td>1.002709e-17</td>\n",
       "      <td>1.002709e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var13_largo</td>\n",
       "      <td>69.327651</td>\n",
       "      <td>8.339222e-17</td>\n",
       "      <td>8.339222e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var13</td>\n",
       "      <td>239.409233</td>\n",
       "      <td>5.290781e-54</td>\n",
       "      <td>5.290781e-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var14_0</td>\n",
       "      <td>0.074954</td>\n",
       "      <td>7.842562e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var14</td>\n",
       "      <td>7.806908</td>\n",
       "      <td>5.204689e-03</td>\n",
       "      <td>5.204689e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var17</td>\n",
       "      <td>0.271889</td>\n",
       "      <td>6.020673e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var24_0</td>\n",
       "      <td>116.505510</td>\n",
       "      <td>3.683543e-27</td>\n",
       "      <td>3.683543e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var24</td>\n",
       "      <td>136.336290</td>\n",
       "      <td>1.684442e-31</td>\n",
       "      <td>1.684442e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var26_0</td>\n",
       "      <td>119.065628</td>\n",
       "      <td>1.013212e-27</td>\n",
       "      <td>1.013212e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var25_0</td>\n",
       "      <td>118.343375</td>\n",
       "      <td>1.458262e-27</td>\n",
       "      <td>1.458262e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_op_var40_hace3</td>\n",
       "      <td>2.719653</td>\n",
       "      <td>9.911959e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var30_0</td>\n",
       "      <td>25.426325</td>\n",
       "      <td>4.596034e-07</td>\n",
       "      <td>4.596034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var30</td>\n",
       "      <td>1125.979600</td>\n",
       "      <td>7.454634e-247</td>\n",
       "      <td>7.454634e-247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var31</td>\n",
       "      <td>3.354180</td>\n",
       "      <td>6.703457e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var32_0</td>\n",
       "      <td>1.704941</td>\n",
       "      <td>1.916430e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var33_0</td>\n",
       "      <td>4.944823</td>\n",
       "      <td>2.616892e-02</td>\n",
       "      <td>2.616892e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var33</td>\n",
       "      <td>3.832238</td>\n",
       "      <td>5.027577e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var39_0</td>\n",
       "      <td>15.580208</td>\n",
       "      <td>7.907802e-05</td>\n",
       "      <td>7.907802e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var40_0</td>\n",
       "      <td>2.101542</td>\n",
       "      <td>1.471507e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var41_0</td>\n",
       "      <td>16.706585</td>\n",
       "      <td>4.362930e-05</td>\n",
       "      <td>4.362930e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var42_0</td>\n",
       "      <td>2.611139</td>\n",
       "      <td>1.061155e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var42</td>\n",
       "      <td>963.980971</td>\n",
       "      <td>1.212406e-211</td>\n",
       "      <td>1.212406e-211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>var36</td>\n",
       "      <td>30050.969675</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>imp_aport_var33_ult1</td>\n",
       "      <td>86.534398</td>\n",
       "      <td>1.373278e-20</td>\n",
       "      <td>1.373278e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_aport_var13_hace3</td>\n",
       "      <td>147.506206</td>\n",
       "      <td>6.082377e-34</td>\n",
       "      <td>6.082377e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_aport_var13_ult1</td>\n",
       "      <td>11.339288</td>\n",
       "      <td>7.588440e-04</td>\n",
       "      <td>7.588440e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_aport_var17_hace3</td>\n",
       "      <td>2.719653</td>\n",
       "      <td>9.911959e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_aport_var17_ult1</td>\n",
       "      <td>20.848768</td>\n",
       "      <td>4.970119e-06</td>\n",
       "      <td>4.970119e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_aport_var33_hace3</td>\n",
       "      <td>2.348791</td>\n",
       "      <td>1.253802e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_aport_var33_ult1</td>\n",
       "      <td>0.741723</td>\n",
       "      <td>3.891094e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_var7_recib_ult1</td>\n",
       "      <td>0.096165</td>\n",
       "      <td>7.564810e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_compra_var44_hace3</td>\n",
       "      <td>3.584996</td>\n",
       "      <td>5.830354e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_compra_var44_ult1</td>\n",
       "      <td>7.391008</td>\n",
       "      <td>6.555073e-03</td>\n",
       "      <td>6.555073e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_meses_var5_ult3</td>\n",
       "      <td>997.714058</td>\n",
       "      <td>5.638295e-219</td>\n",
       "      <td>5.638295e-219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_meses_var8_ult3</td>\n",
       "      <td>81.718539</td>\n",
       "      <td>1.569147e-19</td>\n",
       "      <td>1.569147e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_meses_var12_ult3</td>\n",
       "      <td>107.077913</td>\n",
       "      <td>4.280075e-25</td>\n",
       "      <td>4.280075e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_meses_var13_corto_ult3</td>\n",
       "      <td>142.664448</td>\n",
       "      <td>6.959827e-33</td>\n",
       "      <td>6.959827e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_meses_var13_largo_ult3</td>\n",
       "      <td>40.959615</td>\n",
       "      <td>1.554076e-10</td>\n",
       "      <td>1.554076e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_meses_var17_ult3</td>\n",
       "      <td>4.514503</td>\n",
       "      <td>3.360864e-02</td>\n",
       "      <td>3.360864e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_meses_var29_ult3</td>\n",
       "      <td>0.164827</td>\n",
       "      <td>6.847504e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_meses_var33_ult3</td>\n",
       "      <td>2.843273</td>\n",
       "      <td>9.175713e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_meses_var39_vig_ult3</td>\n",
       "      <td>0.950230</td>\n",
       "      <td>3.296607e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_meses_var44_ult3</td>\n",
       "      <td>3.761207</td>\n",
       "      <td>5.245471e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_op_var40_efect_ult1</td>\n",
       "      <td>265.624238</td>\n",
       "      <td>1.020037e-59</td>\n",
       "      <td>1.020037e-59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_op_var40_efect_ult3</td>\n",
       "      <td>348.525945</td>\n",
       "      <td>8.874375e-78</td>\n",
       "      <td>8.874375e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_reemb_var17_ult1</td>\n",
       "      <td>152.112970</td>\n",
       "      <td>5.985985e-35</td>\n",
       "      <td>5.985985e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_sal_var16_ult1</td>\n",
       "      <td>54.143058</td>\n",
       "      <td>1.864113e-13</td>\n",
       "      <td>1.864113e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_trasp_var17_in_hace3</td>\n",
       "      <td>0.370862</td>\n",
       "      <td>5.425349e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_trasp_var33_in_ult1</td>\n",
       "      <td>0.494482</td>\n",
       "      <td>4.819346e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_venta_var44_ult1</td>\n",
       "      <td>9.766025</td>\n",
       "      <td>1.777664e-03</td>\n",
       "      <td>1.777664e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Chi2        p-Value     associacao\n",
       "num_var1_0                      2.056941   1.515141e-01            NaN\n",
       "num_var4                      245.491116   2.497193e-55   2.497193e-55\n",
       "num_var5_0                      7.597927   5.843544e-03   5.843544e-03\n",
       "num_var5                      987.652698  8.672433e-217  8.672433e-217\n",
       "num_var8_0                    375.266455   1.335196e-83   1.335196e-83\n",
       "num_var12_0                    85.862875   1.928557e-20   1.928557e-20\n",
       "num_var12                     156.720950   5.890152e-36   5.890152e-36\n",
       "num_var13_0                   240.497758   3.063180e-54   3.063180e-54\n",
       "num_var13_corto_0             168.619793   1.481237e-38   1.481237e-38\n",
       "num_var13_corto               171.138710   4.173166e-39   4.173166e-39\n",
       "num_var13_largo_0              73.507177   1.002709e-17   1.002709e-17\n",
       "num_var13_largo                69.327651   8.339222e-17   8.339222e-17\n",
       "num_var13                     239.409233   5.290781e-54   5.290781e-54\n",
       "num_var14_0                     0.074954   7.842562e-01            NaN\n",
       "num_var14                       7.806908   5.204689e-03   5.204689e-03\n",
       "num_var17                       0.271889   6.020673e-01            NaN\n",
       "num_var24_0                   116.505510   3.683543e-27   3.683543e-27\n",
       "num_var24                     136.336290   1.684442e-31   1.684442e-31\n",
       "num_var26_0                   119.065628   1.013212e-27   1.013212e-27\n",
       "num_var25_0                   118.343375   1.458262e-27   1.458262e-27\n",
       "num_op_var40_hace3              2.719653   9.911959e-02            NaN\n",
       "num_var30_0                    25.426325   4.596034e-07   4.596034e-07\n",
       "num_var30                    1125.979600  7.454634e-247  7.454634e-247\n",
       "num_var31                       3.354180   6.703457e-02            NaN\n",
       "num_var32_0                     1.704941   1.916430e-01            NaN\n",
       "num_var33_0                     4.944823   2.616892e-02   2.616892e-02\n",
       "num_var33                       3.832238   5.027577e-02            NaN\n",
       "num_var39_0                    15.580208   7.907802e-05   7.907802e-05\n",
       "num_var40_0                     2.101542   1.471507e-01            NaN\n",
       "num_var41_0                    16.706585   4.362930e-05   4.362930e-05\n",
       "num_var42_0                     2.611139   1.061155e-01            NaN\n",
       "num_var42                     963.980971  1.212406e-211  1.212406e-211\n",
       "var36                       30050.969675   0.000000e+00   0.000000e+00\n",
       "imp_aport_var33_ult1           86.534398   1.373278e-20   1.373278e-20\n",
       "num_aport_var13_hace3         147.506206   6.082377e-34   6.082377e-34\n",
       "num_aport_var13_ult1           11.339288   7.588440e-04   7.588440e-04\n",
       "num_aport_var17_hace3           2.719653   9.911959e-02            NaN\n",
       "num_aport_var17_ult1           20.848768   4.970119e-06   4.970119e-06\n",
       "num_aport_var33_hace3           2.348791   1.253802e-01            NaN\n",
       "num_aport_var33_ult1            0.741723   3.891094e-01            NaN\n",
       "num_var7_recib_ult1             0.096165   7.564810e-01            NaN\n",
       "num_compra_var44_hace3          3.584996   5.830354e-02            NaN\n",
       "num_compra_var44_ult1           7.391008   6.555073e-03   6.555073e-03\n",
       "num_meses_var5_ult3           997.714058  5.638295e-219  5.638295e-219\n",
       "num_meses_var8_ult3            81.718539   1.569147e-19   1.569147e-19\n",
       "num_meses_var12_ult3          107.077913   4.280075e-25   4.280075e-25\n",
       "num_meses_var13_corto_ult3    142.664448   6.959827e-33   6.959827e-33\n",
       "num_meses_var13_largo_ult3     40.959615   1.554076e-10   1.554076e-10\n",
       "num_meses_var17_ult3            4.514503   3.360864e-02   3.360864e-02\n",
       "num_meses_var29_ult3            0.164827   6.847504e-01            NaN\n",
       "num_meses_var33_ult3            2.843273   9.175713e-02            NaN\n",
       "num_meses_var39_vig_ult3        0.950230   3.296607e-01            NaN\n",
       "num_meses_var44_ult3            3.761207   5.245471e-02            NaN\n",
       "num_op_var40_efect_ult1       265.624238   1.020037e-59   1.020037e-59\n",
       "num_op_var40_efect_ult3       348.525945   8.874375e-78   8.874375e-78\n",
       "num_reemb_var17_ult1          152.112970   5.985985e-35   5.985985e-35\n",
       "num_sal_var16_ult1             54.143058   1.864113e-13   1.864113e-13\n",
       "num_trasp_var17_in_hace3        0.370862   5.425349e-01            NaN\n",
       "num_trasp_var33_in_ult1         0.494482   4.819346e-01            NaN\n",
       "num_venta_var44_ult1            9.766025   1.777664e-03   1.777664e-03"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FAZER UM TESTE QUI-QUADRADO ENTRE AS VARIAVEIS CAEGORICAS E A TARGET PARA VERIFICAR A ASSOCIACAO ENTRE ELAS\n",
    "#Chi Quadrado mede a relação de dependência entre duas variáveis categóricas, verificando como os valores esperados\n",
    "# desviam dos valores observados.\n",
    "\n",
    "\n",
    "# Importar metrica\n",
    "from sklearn.feature_selection import chi2\n",
    "# Calculando Chi-Squared\n",
    "chi_scores = chi2(train_set[vars_cat10_2],train_set['TARGET'])\n",
    "# Colocando label nos resultados para posterior plot\n",
    "scores = pd.Series(chi_scores[0], index=vars_cat10_2)\n",
    "pvalues = pd.Series(chi_scores[1], index=vars_cat10_2)\n",
    "\n",
    "# Results\n",
    "teste_chi = pd.DataFrame({'Chi2':scores, 'p-Value':pvalues})\n",
    "teste_chi['associacao'] = teste_chi[teste_chi['p-Value'] <= 0.05]['p-Value']\n",
    "teste_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "to_drop_3 = []\n",
    "to_drop_3 = [columns for columns in teste_chi[teste_chi['p-Value'] > 0.05].index]\n",
    "print(len(to_drop_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Binarias 80\n",
      "#Ate 10 categorias 40\n",
      "#Continuas 147\n"
     ]
    }
   ],
   "source": [
    "vars_cat10_3 = []\n",
    "\n",
    "vars_cat10_3 = [columns for columns in features_2[vars_cat10_2].columns if columns not in to_drop_3]\n",
    "print('#Binarias',len(vars_bin))\n",
    "print('#Ate 10 categorias',len(vars_cat10_3))\n",
    "print('#Continuas',len(vars_cont_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_var4',\n",
       " 'num_var5_0',\n",
       " 'num_var5',\n",
       " 'num_var8_0',\n",
       " 'num_var12_0',\n",
       " 'num_var12',\n",
       " 'num_var13_0',\n",
       " 'num_var13_corto_0',\n",
       " 'num_var13_corto',\n",
       " 'num_var13_largo_0',\n",
       " 'num_var13_largo',\n",
       " 'num_var13',\n",
       " 'num_var14',\n",
       " 'num_var24_0',\n",
       " 'num_var24',\n",
       " 'num_var26_0',\n",
       " 'num_var25_0',\n",
       " 'num_var30_0',\n",
       " 'num_var30',\n",
       " 'num_var33_0',\n",
       " 'num_var39_0',\n",
       " 'num_var41_0',\n",
       " 'num_var42',\n",
       " 'var36',\n",
       " 'imp_aport_var33_ult1',\n",
       " 'num_aport_var13_hace3',\n",
       " 'num_aport_var13_ult1',\n",
       " 'num_aport_var17_ult1',\n",
       " 'num_compra_var44_ult1',\n",
       " 'num_meses_var5_ult3',\n",
       " 'num_meses_var8_ult3',\n",
       " 'num_meses_var12_ult3',\n",
       " 'num_meses_var13_corto_ult3',\n",
       " 'num_meses_var13_largo_ult3',\n",
       " 'num_meses_var17_ult3',\n",
       " 'num_op_var40_efect_ult1',\n",
       " 'num_op_var40_efect_ult3',\n",
       " 'num_reemb_var17_ult1',\n",
       " 'num_sal_var16_ult1',\n",
       " 'num_venta_var44_ult1']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_cat10_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chi2</th>\n",
       "      <th>p-Value</th>\n",
       "      <th>associacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ind_var1_0</td>\n",
       "      <td>0.395146</td>\n",
       "      <td>5.296068e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ind_var1</td>\n",
       "      <td>7.387847</td>\n",
       "      <td>6.566605e-03</td>\n",
       "      <td>6.566605e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ind_var5_0</td>\n",
       "      <td>2.824111</td>\n",
       "      <td>9.285828e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ind_var5</td>\n",
       "      <td>330.017318</td>\n",
       "      <td>9.528301e-74</td>\n",
       "      <td>9.528301e-74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ind_var6_0</td>\n",
       "      <td>0.247241</td>\n",
       "      <td>6.190244e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_trasp_var17_in_ult1</td>\n",
       "      <td>0.494482</td>\n",
       "      <td>4.819346e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_trasp_var17_out_ult1</td>\n",
       "      <td>0.370862</td>\n",
       "      <td>5.425349e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_trasp_var33_in_hace3</td>\n",
       "      <td>0.370862</td>\n",
       "      <td>5.425349e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_trasp_var33_out_ult1</td>\n",
       "      <td>0.123621</td>\n",
       "      <td>7.251404e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_venta_var44_hace3</td>\n",
       "      <td>0.123621</td>\n",
       "      <td>7.251404e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Chi2       p-Value    associacao\n",
       "ind_var1_0                  0.395146  5.296068e-01           NaN\n",
       "ind_var1                    7.387847  6.566605e-03  6.566605e-03\n",
       "ind_var5_0                  2.824111  9.285828e-02           NaN\n",
       "ind_var5                  330.017318  9.528301e-74  9.528301e-74\n",
       "ind_var6_0                  0.247241  6.190244e-01           NaN\n",
       "...                              ...           ...           ...\n",
       "num_trasp_var17_in_ult1     0.494482  4.819346e-01           NaN\n",
       "num_trasp_var17_out_ult1    0.370862  5.425349e-01           NaN\n",
       "num_trasp_var33_in_hace3    0.370862  5.425349e-01           NaN\n",
       "num_trasp_var33_out_ult1    0.123621  7.251404e-01           NaN\n",
       "num_venta_var44_hace3       0.123621  7.251404e-01           NaN\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FAZER UM TESTE QUI-QUADRADO ENTRE AS VARIAVEIS BINARIAS E A TARGET PARA VERIFICAR A ASSOCIACAO ENTRE ELAS\n",
    "#Chi Quadrado mede a relação de dependência entre duas variáveis categóricas, verificando como os valores esperados\n",
    "# desviam dos valores observados.\n",
    "\n",
    "\n",
    "# Importar metrica\n",
    "from sklearn.feature_selection import chi2\n",
    "# Calculando Chi-Squared\n",
    "chi_scores = chi2(train_set[vars_bin],train_set['TARGET'])\n",
    "# Colocando label nos resultados para posterior plot\n",
    "scores = pd.Series(chi_scores[0], index=vars_bin)\n",
    "pvalues = pd.Series(chi_scores[1], index=vars_bin)\n",
    "\n",
    "# Results\n",
    "teste_chi_bin = pd.DataFrame({'Chi2':scores, 'p-Value':pvalues})\n",
    "teste_chi_bin['associacao'] = teste_chi_bin[teste_chi_bin['p-Value'] <= 0.05]['p-Value']\n",
    "teste_chi_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "to_drop_4 = []\n",
    "to_drop_4 = [columns for columns in teste_chi_bin[teste_chi_bin['p-Value'] > 0.05].index]\n",
    "print(len(to_drop_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Binarias 45\n",
      "#Ate 10 categorias 40\n",
      "#Continuas 147\n"
     ]
    }
   ],
   "source": [
    "vars_bin_2 = []\n",
    "\n",
    "vars_bin_2 = [columns for columns in features_2[vars_bin].columns if columns not in to_drop_4]\n",
    "print('#Binarias',len(vars_bin_2))\n",
    "print('#Ate 10 categorias',len(vars_cat10_3))\n",
    "print('#Continuas',len(vars_cont_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ind_var1',\n",
       " 'ind_var5',\n",
       " 'ind_var8_0',\n",
       " 'ind_var8',\n",
       " 'ind_var12_0',\n",
       " 'ind_var12',\n",
       " 'ind_var13_0',\n",
       " 'ind_var13_corto_0',\n",
       " 'ind_var13_corto',\n",
       " 'ind_var13_largo_0',\n",
       " 'ind_var13_largo',\n",
       " 'ind_var13',\n",
       " 'ind_var14_0',\n",
       " 'ind_var19',\n",
       " 'ind_var20_0',\n",
       " 'ind_var20',\n",
       " 'ind_var24_0',\n",
       " 'ind_var24',\n",
       " 'ind_var25_cte',\n",
       " 'ind_var26_0',\n",
       " 'ind_var26_cte',\n",
       " 'ind_var25_0',\n",
       " 'ind_var30',\n",
       " 'ind_var31_0',\n",
       " 'ind_var39_0',\n",
       " 'ind_var40',\n",
       " 'ind_var41_0',\n",
       " 'num_var1',\n",
       " 'num_var8',\n",
       " 'num_var20_0',\n",
       " 'num_var20',\n",
       " 'num_var40',\n",
       " 'saldo_var18',\n",
       " 'delta_imp_amort_var18_1y3',\n",
       " 'delta_imp_reemb_var13_1y3',\n",
       " 'delta_imp_reemb_var17_1y3',\n",
       " 'delta_imp_trasp_var17_out_1y3',\n",
       " 'delta_imp_trasp_var33_out_1y3',\n",
       " 'imp_amort_var18_ult1',\n",
       " 'imp_trasp_var33_out_ult1',\n",
       " 'imp_venta_var44_hace3',\n",
       " 'ind_var10_ult1',\n",
       " 'ind_var10cte_ult1',\n",
       " 'ind_var9_ult1',\n",
       " 'ind_var43_recib_ult1']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_bin_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>61553</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>48.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>209.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175887.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6865</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111297.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40817</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80805.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71630</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124585.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "61553     2     38                48.0                    102.0   \n",
       "6865      2     51                 0.0                      0.0   \n",
       "847       2     23                 0.0                      0.0   \n",
       "40817     2     23                 0.0                      0.0   \n",
       "71630     2     23                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "61553                    209.7                      0.0   \n",
       "6865                       0.0                      0.0   \n",
       "847                        0.0                      0.0   \n",
       "40817                      0.0                      0.0   \n",
       "71630                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "61553                      0.0                      0.0   \n",
       "6865                       0.0                      0.0   \n",
       "847                        0.0                      0.0   \n",
       "40817                      0.0                      0.0   \n",
       "71630                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "61553                      0.0                0.0  ...   \n",
       "6865                       0.0                0.0  ...   \n",
       "847                        0.0                0.0  ...   \n",
       "40817                      0.0                0.0  ...   \n",
       "71630                      0.0                0.0  ...   \n",
       "\n",
       "       saldo_medio_var29_ult3  saldo_medio_var33_hace2  \\\n",
       "61553                     0.0                      0.0   \n",
       "6865                      0.0                      0.0   \n",
       "847                       0.0                      0.0   \n",
       "40817                     0.0                      0.0   \n",
       "71630                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "61553                      0.0                     0.0   \n",
       "6865                       0.0                     0.0   \n",
       "847                        0.0                     0.0   \n",
       "40817                      0.0                     0.0   \n",
       "71630                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "61553                     0.0                      0.0   \n",
       "6865                      0.0                      0.0   \n",
       "847                       0.0                      0.0   \n",
       "40817                     0.0                      0.0   \n",
       "71630                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "61553                      0.0                     0.0   \n",
       "6865                       0.0                     0.0   \n",
       "847                        0.0                     0.0   \n",
       "40817                      0.0                     0.0   \n",
       "71630                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  \n",
       "61553                     0.0  175887.150000  \n",
       "6865                      0.0  111297.030000  \n",
       "847                       0.0  117310.979016  \n",
       "40817                     0.0   80805.900000  \n",
       "71630                     0.0  124585.620000  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_3 = features_2.drop(to_drop_3, axis=1).drop(to_drop_4, axis=1)\n",
    "features_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERIFICAR SE AS VARIAVEIS SAO ORDINAIS EM RELACAO A TARGET, SENAO, FAZER ENCODING OOOOU PARAR AQUI????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRIAR VARIAVEL QUE IDENTIFICA OS CLIENTES QUE ESTAO NO RANGE DOS OUTLIERS EM TODAS AS VARIAVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SELECTION - RANDOM FOREST - GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 232), (53214,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separa X e Y de treino\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_train = train_set[features_3.columns]\n",
    "y_train = train_set['TARGET']\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brunaoliveira/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# #Cria var aleatoria\n",
    "\n",
    "# x_train['random_var'] = np.random.rand(x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Log loss: 0.766\n"
     ]
    }
   ],
   "source": [
    "#Como os dados nao sao balanceados\n",
    "#Another approach to make random forest more suitable for learning from extremely imbalanced data follows the idea of cost\n",
    "# sensitive learning. Since the RF classifier tends to be biased towards the majority class, we shall place a heavier penalty\n",
    "# on misclassifying the minority class.\n",
    "#class weight = balanced -> This argument takes a dictionary with a mapping of each class value (e.g. 0 and 1) to the weighting. The argument value of\n",
    "# ‘balanced‘ can be provided to automatically use the inverse weighting from the training dataset, giving focus to the\n",
    "# minority class.\n",
    "#class_weight='balanced_subsample' -> Given that each decision tree is constructed from a bootstrap sample (e.g. random selection with replacement), the class\n",
    "# distribution in the data sample will be different for each tree.\n",
    "#As such, it might be interesting to change the class weighting based on the class distribution in each bootstrap sample,\n",
    "# instead of the entire training dataset.\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 10, class_weight='balanced_subsample',random_state=42)\n",
    "\n",
    "scores = cross_val_score(rnd_clf, x_train, y_train, scoring='neg_log_loss', cv=10) #para classificacao o cv ja eh estratificado pela target\n",
    "\n",
    "print('Media Log loss: %.3f' % (-1*(mean(scores))))\n",
    "# print('Media Lucro Relativo: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'class_weight': ['balanced_subsample'],\n",
       "                         'criterion': ['gini'], 'max_depth': range(5, 20, 5),\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [30, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Faz Grid Search para ver se teriamos algum valor melhor para os hiperparametros\n",
    "#Foi testado 'n_estimators': [10,30,50] E 'max_depth': range(5,50,10) E 'max_features': ['sqrt','log2'] -> best = 50, 5, sqrt\n",
    "#Foi testado 'n_estimators': [30,50,100] E 'max_depth': range(5,20,10) E 'max_features': ['sqrt','log2'] -> best = 100, 5, sqrt\n",
    "\n",
    "grid_param = {\n",
    "    'n_estimators': [30,50,100],\n",
    "    'criterion': ['gini'], #default\n",
    "    'max_depth': range(5,20,5),\n",
    "    'max_features': ['sqrt','log2'],\n",
    "    'class_weight':['balanced_subsample']\n",
    "}\n",
    "\n",
    "rnd_clf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(rnd_clf,grid_param,scoring='neg_log_loss',cv=10)\n",
    "\n",
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "                       criterion='gini', max_depth=15, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced_subsample',\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 15,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5476685129013728 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 30}\n",
      "-0.54625294437333 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}\n",
      "-0.5466637780534187 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "-0.5765363491273566 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 30}\n",
      "-0.577057605824777 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 50}\n",
      "-0.5748982920438056 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 100}\n",
      "-0.459344016356608 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 30}\n",
      "-0.45654272847017774 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 50}\n",
      "-0.45835787755112906 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "-0.5083308901319168 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 30}\n",
      "-0.5066230454920113 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 50}\n",
      "-0.5043223114433183 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100}\n",
      "-0.39197171142178777 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 30}\n",
      "-0.38769010249825553 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 50}\n",
      "-0.3858731128091728 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "-0.44160567554842484 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'log2', 'n_estimators': 30}\n",
      "-0.4356993657264058 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'log2', 'n_estimators': 50}\n",
      "-0.43675306404388875 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'log2', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'],cvres['params']):\n",
    "    print(mean_score,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Log loss: 0.385\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(criterion = 'gini',\n",
    " max_depth = 15,\n",
    " max_features = 'sqrt',\n",
    " n_estimators = 100,\n",
    " class_weight = 'balanced_subsample', random_state=42)\n",
    "\n",
    "scores = cross_val_score(rnd_clf, x_train, y_train, scoring='neg_log_loss', cv=10) #para classificacao o cv ja eh estratificado pela target\n",
    "\n",
    "print('Media Log loss: %.3f' % (-1*mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var38                           0.208277\n",
       "var15                           0.200346\n",
       "saldo_medio_var5_hace3          0.059214\n",
       "saldo_medio_var5_ult3           0.039496\n",
       "saldo_var5                      0.026001\n",
       "                                  ...   \n",
       "delta_imp_reemb_var13_1y3       0.000000\n",
       "delta_imp_reemb_var17_1y3       0.000000\n",
       "ind_var20                       0.000000\n",
       "delta_imp_trasp_var17_in_1y3    0.000000\n",
       "imp_aport_var17_hace3           0.000000\n",
       "Length: 232, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.fit(x_train,y_train)\n",
    "\n",
    "feature_scores = pd.Series(rnd_clf.feature_importances_, index=x_train.columns).sort_values(ascending=False)\n",
    "\n",
    "feature_scores.to_csv('feature_importance.csv',header=False)\n",
    "\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_scores.get(key='random_var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (feature_scores <= feature_scores.get(key='random_var')).sum()\n",
    "(feature_scores <= 0.01).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ed135d3d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x640 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "feat_importance = pd.Series(rnd_clf.feature_importances_, index= x_train.columns)\n",
    "\n",
    "feat_importance.nlargest(19).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_4 = []\n",
    "# to_drop_4 = feature_scores.loc[lambda x: x <= feature_scores.get(key='random_var')].index[1:]\n",
    "to_drop_4 = feature_scores.loc[lambda x: x <= 0.01].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var15</th>\n",
       "      <th>ind_var5</th>\n",
       "      <th>ind_var30</th>\n",
       "      <th>num_var30</th>\n",
       "      <th>num_var42</th>\n",
       "      <th>saldo_var5</th>\n",
       "      <th>saldo_var30</th>\n",
       "      <th>saldo_var42</th>\n",
       "      <th>num_var22_ult3</th>\n",
       "      <th>num_med_var45_ult3</th>\n",
       "      <th>num_var45_hace2</th>\n",
       "      <th>num_var45_hace3</th>\n",
       "      <th>num_var45_ult1</th>\n",
       "      <th>num_var45_ult3</th>\n",
       "      <th>saldo_medio_var5_hace2</th>\n",
       "      <th>saldo_medio_var5_hace3</th>\n",
       "      <th>saldo_medio_var5_ult1</th>\n",
       "      <th>saldo_medio_var5_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>61553</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>64139.49</td>\n",
       "      <td>64139.49</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>129.18</td>\n",
       "      <td>12.60</td>\n",
       "      <td>176.07</td>\n",
       "      <td>105.96</td>\n",
       "      <td>175887.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6865</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.23</td>\n",
       "      <td>111297.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40817</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80805.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71630</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>91.98</td>\n",
       "      <td>68.28</td>\n",
       "      <td>120.00</td>\n",
       "      <td>93.42</td>\n",
       "      <td>124585.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       var15  ind_var5  ind_var30  num_var30  num_var42  saldo_var5  \\\n",
       "61553     38         1          1          6          6         0.3   \n",
       "6865      51         1          1          3          3         1.5   \n",
       "847       23         1          1          3          3         3.0   \n",
       "40817     23         0          0          0          0         0.0   \n",
       "71630     23         1          1          3          3       120.0   \n",
       "\n",
       "       saldo_var30  saldo_var42  num_var22_ult3  num_med_var45_ult3  \\\n",
       "61553     64139.49     64139.49               3                   9   \n",
       "6865          1.50         1.50               3                   0   \n",
       "847           3.00         3.00               0                   0   \n",
       "40817         0.00         0.00               0                   0   \n",
       "71630       120.00       120.00               9                   3   \n",
       "\n",
       "       num_var45_hace2  num_var45_hace3  num_var45_ult1  num_var45_ult3  \\\n",
       "61553               15                3              12              30   \n",
       "6865                 0                3               3               6   \n",
       "847                  0                0               0               0   \n",
       "40817                0                0               0               0   \n",
       "71630               12                0               0              12   \n",
       "\n",
       "       saldo_medio_var5_hace2  saldo_medio_var5_hace3  saldo_medio_var5_ult1  \\\n",
       "61553                  129.18                   12.60                 176.07   \n",
       "6865                     1.50                    0.72                   1.50   \n",
       "847                      3.00                    0.72                   3.00   \n",
       "40817                    0.00                    0.00                   0.00   \n",
       "71630                   91.98                   68.28                 120.00   \n",
       "\n",
       "       saldo_medio_var5_ult3          var38  \n",
       "61553                 105.96  175887.150000  \n",
       "6865                    1.23  111297.030000  \n",
       "847                     2.25  117310.979016  \n",
       "40817                   0.00   80805.900000  \n",
       "71630                  93.42  124585.620000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_4 = features_3.drop(to_drop_4, axis=1)\n",
    "features_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 19), (53214,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separa X e Y de treino\n",
    "x_train_fs = []\n",
    "y_train_fs = []\n",
    "x_train_fs = train_set[features_4.columns]\n",
    "y_train_fs = train_set['TARGET']\n",
    "x_train_fs.shape, y_train_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Log loss: 0.314\n"
     ]
    }
   ],
   "source": [
    "rnd_clf_fs = RandomForestClassifier(criterion = 'gini',\n",
    " max_depth = 15,\n",
    " max_features = 'sqrt',\n",
    " n_estimators = 100,\n",
    " class_weight = 'balanced_subsample', random_state=42)\n",
    "\n",
    "scores_fs = cross_val_score(rnd_clf_fs, x_train_fs, y_train_fs, scoring='neg_log_loss', cv=10) #para classificacao o cv ja eh estratificado pela target\n",
    "\n",
    "print('Media Log loss: %.3f' % (-1*mean(scores_fs)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 19), (53214,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separa X e Y de treino\n",
    "x_train = train_set[features_4.columns]\n",
    "y_train = train_set['TARGET']\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22806, 19), (22806,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separa X e Y de treino\n",
    "x_test = test_set[features_4.columns]\n",
    "y_test = test_set['TARGET']\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcao de Lucro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao que verifica se o lucro do modelo se aproxima do lucro max que poderia ter\n",
    "\n",
    "def funcao_lucro(y_true, y_pred):\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred).ravel().tolist()\n",
    "    fp = cm[1]\n",
    "    tp = cm[3]\n",
    "\n",
    "    lucro_max = sum(y_true)*90\n",
    "    \n",
    "    f_lucro = ((-10*fp)+(90*tp))/lucro_max\n",
    "\n",
    "    return f_lucro\n",
    "\n",
    "lucro = make_scorer(funcao_lucro, greater_is_better=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lucro Maximo (100% acerto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucro Maximo: 189540.00\n"
     ]
    }
   ],
   "source": [
    "LM = sum(y_train)*90\n",
    "print('Lucro Maximo: %.2f' % LM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acao para todos os clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.500\n",
      "Lucro Relativo: -1.696\n",
      "Lucro Total: -321540.00\n",
      "F1: 0.076\n",
      "Log Loss: 33.173\n"
     ]
    }
   ],
   "source": [
    "y_acao = pd.Series(np.ones(len(y_train)),name='TARGET',dtype=int)\n",
    "\n",
    "auc = roc_auc_score(y_train, y_acao.to_list())\n",
    "print('ROC AUC: %.3f' % auc)\n",
    "LR = funcao_lucro(y_train,y_acao.to_list())\n",
    "print('Lucro Relativo: %.3f' % LR)\n",
    "print('Lucro Total: %.2f' % (LR*LM))\n",
    "F1 = f1_score(y_train, y_acao.to_list())\n",
    "print('F1: %.3f' % F1)\n",
    "LL = log_loss(y_train,y_acao.to_list())\n",
    "print('Log Loss: %.3f' % LL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerar um modelo com Gradiente Boosting\n",
    "#implementacao otimizada: XGBoost - rapido, escalonavel e portatil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.902\n",
      "ROC AUC Teste: 0.725\n",
      "Lucro Relativo: 0.573\n",
      "Lucro Relativo Teste: 0.199\n",
      "Lucro Total: 108580.00\n",
      "Lucro Total Teste: 37660.51\n",
      "F1: 0.359\n",
      "F1 Teste: 0.230\n",
      "Log Loss: 4.595\n",
      "Log Loss Teste: 5.442\n"
     ]
    }
   ],
   "source": [
    "#Treinando e Testando o modelo base\n",
    "XGB = XGBClassifier(\n",
    "   scale_pos_weight = sum(y_train == 0) / sum(y_train == 1),\n",
    "   # max_depth = 6,\n",
    "   # learning_rate = 0.01,\n",
    "   random_state = 42\n",
    ")\n",
    "XGB.fit(x_train,y_train)\n",
    "y_p_train = XGB.predict(x_train)\n",
    "y_p_test = XGB.predict(x_test)\n",
    "\n",
    "auc = roc_auc_score(y_train, y_p_train)\n",
    "auc_test = roc_auc_score(y_test, y_p_test)\n",
    "print('ROC AUC: %.3f' % auc)\n",
    "print('ROC AUC Teste: %.3f' % auc_test)\n",
    "\n",
    "LR = funcao_lucro(y_train, y_p_train)\n",
    "LR_test = funcao_lucro(y_test, y_p_test)\n",
    "print('Lucro Relativo: %.3f' % LR)\n",
    "print('Lucro Relativo Teste: %.3f' % LR_test)\n",
    "print('Lucro Total: %.2f' % (LR*LM))\n",
    "print('Lucro Total Teste: %.2f' % (LR_test*LM))\n",
    "\n",
    "F1 = f1_score(y_train, y_p_train)\n",
    "F1_test = f1_score(y_test, y_p_test)\n",
    "print('F1: %.3f' % F1)\n",
    "print('F1 Teste: %.3f' % F1_test)\n",
    "\n",
    "LL = log_loss(y_train, y_p_train)\n",
    "LL_test = log_loss(y_test, y_p_test)\n",
    "print('Log Loss: %.3f' % LL)\n",
    "print('Log Loss Teste: %.3f' % LL_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'eval_metric': None,\n",
       " 'gamma': 0,\n",
       " 'gpu_id': -1,\n",
       " 'grow_policy': 'depthwise',\n",
       " 'interaction_constraints': '',\n",
       " 'learning_rate': 0.300000012,\n",
       " 'max_bin': 256,\n",
       " 'max_cat_to_onehot': 4,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'max_leaves': 0,\n",
       " 'min_child_weight': 1,\n",
       " 'monotone_constraints': '()',\n",
       " 'n_jobs': 0,\n",
       " 'num_parallel_tree': 1,\n",
       " 'predictor': 'auto',\n",
       " 'random_state': 42,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'sampling_method': 'uniform',\n",
       " 'scale_pos_weight': 24.267806267806268,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact',\n",
       " 'validate_parameters': 1,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB.get_xgb_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuna hiperparametros\n",
    "#Faz grid search para selecionar os melhores hiperparametros\n",
    "#Feature selection\n",
    "#grafico de aumento de vars por aumento de lucro (menor complexidade vs maior lucro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz Random Search para ver se teriamos algum valor melhor para os hiperparametros\n",
    "#Random Search eh melhor para tunar hiperparametros com XGBoost, pois ele considera algumas combinacoes aleatorias de parametros e nao\n",
    "# todas (como o Grid Search). Logo, como o XGBoost faz modelos sequenciais e, consequentemente, demora mais, melhor usar o Random. \n",
    "#https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "\n",
    "#Fiz 'learning_rate': np.arange(0.1,1.01,0.2) -> 0.1\n",
    "\n",
    "XGB_grid_param = {\n",
    "    'n_estimators': range(10,100,10),\n",
    "    'max_depth': range(3,13,3), #default 6\n",
    "    'learning_rate': [0.001,0.01,0.1], #default 0,3\n",
    "    'subsample': np.arange(0.25,1.01,0.25), #default 1\n",
    "    'colsample_bytree': np.arange(0.25,1.01,0.25), #default 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           callbacks=None, colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=0, gpu_id=-1,\n",
       "                                           grow_policy='depthwise',\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints='',\n",
       "                                           learni...\n",
       "                                           reg_alpha=0, ...),\n",
       "                   iid='warn', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': array([0.25, 0.5 , 0.75, 1.  ]),\n",
       "                                        'learning_rate': [0.001, 0.01, 0.1],\n",
       "                                        'max_depth': range(3, 13, 3),\n",
       "                                        'n_estimators': range(10, 100, 10),\n",
       "                                        'subsample': array([0.25, 0.5 , 0.75, 1.  ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(estimator=XGB, \n",
    "                           param_distributions=XGB_grid_param,\n",
    "                           n_iter=100,\n",
    "                           scoring='neg_log_loss', \n",
    "                           n_jobs=-1, \n",
    "                           cv=5)\n",
    "\n",
    "random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1.0,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=12, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=90, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='binary:logistic',\n",
       "              predictor='auto', random_state=42, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.75,\n",
       " 'n_estimators': 90,\n",
       " 'max_depth': 12,\n",
       " 'learning_rate': 0.1,\n",
       " 'colsample_bytree': 1.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([13.26843262, 16.56655569, 11.23140769, 13.93937078,  0.86766777,\n",
       "         4.82858782,  7.38948741, 26.42498651,  5.17203002,  2.12703519,\n",
       "        23.87137809,  4.5381937 ,  3.6719871 , 35.28679214,  4.15948281,\n",
       "         6.03553143,  9.06929893,  1.49227996,  1.08233232,  3.62501965,\n",
       "        11.50649238, 13.74818687, 15.5018384 ,  3.03446331,  2.75120773,\n",
       "         7.68100252,  5.81132374, 18.30661983,  5.76865468,  4.17913952,\n",
       "         7.05362406, 11.45099115, 17.25128303,  9.97796879,  2.60304041,\n",
       "        25.39945927,  6.94355803, 21.2623157 ,  1.62424879,  1.29423862,\n",
       "        11.69851151, 12.54156523, 12.68813357,  6.59157839,  8.04002433,\n",
       "        17.5529026 , 11.11711664, 16.4340044 ,  1.74054246,  1.88750854,\n",
       "         3.85013213,  2.56141639,  2.4258554 ,  1.29341602,  7.24677615,\n",
       "         8.28088188, 10.92665281,  1.69201951, 31.90888286, 10.35121136,\n",
       "         6.86919098,  4.13315721, 10.63396497,  9.76805043,  6.10980496,\n",
       "        11.85153356,  0.86322694,  4.01754236, 11.74883223,  1.17379003,\n",
       "         6.25720077,  2.31689401,  4.141257  ,  6.08778267, 19.48054872,\n",
       "         9.0794816 , 10.02091656,  2.58914156,  0.69603672,  2.94798832,\n",
       "         3.64008102,  0.63278527,  8.42303596,  3.49555764,  5.91755114,\n",
       "        15.78500147,  4.25293746,  1.27481909,  8.30079389,  4.6839664 ,\n",
       "        17.4673708 , 12.0213912 ,  4.67854247,  6.61110902, 12.7643929 ,\n",
       "         6.44948277,  7.9281908 , 10.99930673, 17.57027092,  2.77469039]),\n",
       " 'std_fit_time': array([0.57395114, 1.21859386, 1.7251651 , 0.16610671, 0.01891679,\n",
       "        0.12692974, 0.11739399, 0.66170514, 0.06754306, 0.02156517,\n",
       "        0.67239426, 0.49913931, 0.04959656, 0.18540081, 0.02080672,\n",
       "        0.07834086, 0.40391049, 0.10840082, 0.0777153 , 0.06749647,\n",
       "        0.14270844, 0.37199927, 0.31717451, 0.0839976 , 0.19002839,\n",
       "        0.20558242, 0.2934327 , 1.13657657, 0.53722042, 0.35005559,\n",
       "        0.19157355, 0.78375885, 0.73184133, 0.21641418, 0.27519174,\n",
       "        3.84198175, 0.52608699, 5.03873692, 0.16266164, 0.06701048,\n",
       "        1.16719213, 1.60454971, 0.52354324, 0.6534511 , 0.40441382,\n",
       "        0.58607464, 1.16594903, 1.81094142, 0.08335525, 0.01520914,\n",
       "        0.69379581, 0.24306453, 0.13828485, 0.03795952, 0.53571688,\n",
       "        0.68591875, 1.05041501, 0.15122791, 0.74781608, 0.75318113,\n",
       "        1.21936732, 0.46992055, 0.39252861, 1.18521904, 0.85243813,\n",
       "        1.17116913, 0.0170628 , 0.09625498, 0.61915735, 0.0262083 ,\n",
       "        0.18252364, 0.14410925, 0.05369237, 0.06155928, 1.13154204,\n",
       "        0.60463762, 0.48240702, 0.07324453, 0.08306951, 0.02201902,\n",
       "        0.03457372, 0.013875  , 0.85322618, 0.34862754, 0.76674566,\n",
       "        0.28542211, 0.64568031, 0.09125666, 0.59977226, 0.02868538,\n",
       "        1.28042983, 2.20718814, 0.85643866, 0.40610279, 0.7566369 ,\n",
       "        1.21036322, 0.51120169, 2.47937924, 3.22693383, 0.2542391 ]),\n",
       " 'mean_score_time': array([0.09591146, 0.13893027, 0.07890115, 0.11030197, 0.03753357,\n",
       "        0.09658895, 0.05023885, 0.1330862 , 0.05310979, 0.05052719,\n",
       "        0.13857141, 0.05533733, 0.04832163, 0.1967618 , 0.04113584,\n",
       "        0.08258157, 0.0584301 , 0.04610724, 0.07650967, 0.06408896,\n",
       "        0.08038726, 0.12633872, 0.14523921, 0.06230664, 0.0613729 ,\n",
       "        0.11234384, 0.04686446, 0.15796518, 0.06850719, 0.05727301,\n",
       "        0.07425513, 0.21315923, 0.12217708, 0.08290648, 0.0437315 ,\n",
       "        0.17276134, 0.12969146, 0.17373962, 0.03855114, 0.04814196,\n",
       "        0.14751263, 0.07763243, 0.1325841 , 0.09352789, 0.11017299,\n",
       "        0.19726915, 0.099332  , 0.09413519, 0.04811516, 0.03800845,\n",
       "        0.04342961, 0.06098037, 0.063131  , 0.04468417, 0.05143356,\n",
       "        0.04967952, 0.07079854, 0.04059477, 0.13428712, 0.10341792,\n",
       "        0.06165738, 0.05325632, 0.09705315, 0.17814012, 0.13466787,\n",
       "        0.12330298, 0.04186883, 0.05999107, 0.08467598, 0.0474483 ,\n",
       "        0.11162677, 0.04477582, 0.06569562, 0.07986131, 0.10425782,\n",
       "        0.08092542, 0.07775288, 0.03882318, 0.03486853, 0.05606289,\n",
       "        0.04956141, 0.03885012, 0.06788855, 0.07279296, 0.07967324,\n",
       "        0.07810688, 0.0853282 , 0.04249172, 0.10556765, 0.04761705,\n",
       "        0.09657741, 0.07081094, 0.05955772, 0.04359846, 0.1202075 ,\n",
       "        0.05771623, 0.07246866, 0.09171753, 0.11765714, 0.03437781]),\n",
       " 'std_score_time': array([0.00754537, 0.05175837, 0.00184904, 0.00713956, 0.00264796,\n",
       "        0.0129029 , 0.00686284, 0.00684883, 0.00444435, 0.02092743,\n",
       "        0.00599989, 0.01380297, 0.00415191, 0.02363399, 0.00293534,\n",
       "        0.00543502, 0.00313133, 0.00400487, 0.05664252, 0.00204322,\n",
       "        0.00242597, 0.00748718, 0.0184961 , 0.00468384, 0.00732811,\n",
       "        0.00289489, 0.00317347, 0.02686947, 0.01297933, 0.00693239,\n",
       "        0.0058036 , 0.07204774, 0.03411122, 0.01124283, 0.01355427,\n",
       "        0.09223153, 0.03891034, 0.01854459, 0.00146927, 0.01734262,\n",
       "        0.01669446, 0.01602129, 0.02507499, 0.00467422, 0.06201156,\n",
       "        0.05724686, 0.02481695, 0.0487271 , 0.00644241, 0.00356637,\n",
       "        0.00756507, 0.0336451 , 0.00666131, 0.00985122, 0.0070317 ,\n",
       "        0.00314778, 0.00508423, 0.00522489, 0.02134848, 0.03088894,\n",
       "        0.02543552, 0.00413778, 0.01649617, 0.13352029, 0.0674082 ,\n",
       "        0.03299375, 0.00727495, 0.00753542, 0.03920198, 0.00641608,\n",
       "        0.02750698, 0.00205185, 0.00389373, 0.00975309, 0.0127575 ,\n",
       "        0.00226616, 0.01436172, 0.01110438, 0.00916603, 0.00552771,\n",
       "        0.00710835, 0.00389262, 0.01783573, 0.05925047, 0.01667284,\n",
       "        0.01473528, 0.02942988, 0.01009494, 0.01060629, 0.00286805,\n",
       "        0.03449151, 0.00977823, 0.02669972, 0.00471175, 0.04402123,\n",
       "        0.02988679, 0.01332671, 0.01522681, 0.02175468, 0.00416357]),\n",
       " 'param_subsample': masked_array(data=[0.25, 0.75, 0.75, 0.5, 1.0, 0.25, 0.75, 0.75, 0.75,\n",
       "                    0.25, 0.75, 0.25, 1.0, 0.75, 1.0, 0.25, 0.5, 0.75,\n",
       "                    0.25, 0.5, 0.75, 1.0, 0.75, 1.0, 0.75, 0.5, 0.5, 0.25,\n",
       "                    0.25, 0.75, 0.75, 0.25, 0.25, 0.25, 0.25, 1.0, 0.25,\n",
       "                    0.25, 0.75, 0.25, 1.0, 0.5, 0.75, 0.5, 0.75, 1.0, 0.25,\n",
       "                    0.75, 0.25, 1.0, 0.75, 0.25, 0.25, 0.5, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.25, 0.5, 0.5, 0.75,\n",
       "                    0.25, 1.0, 0.25, 0.75, 0.25, 0.5, 0.25, 0.5, 0.25,\n",
       "                    0.75, 1.0, 0.25, 0.75, 0.25, 0.25, 0.5, 0.75, 0.5, 1.0,\n",
       "                    1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0,\n",
       "                    0.75, 0.5, 0.25, 0.25],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[90, 50, 90, 50, 20, 90, 70, 80, 90, 30, 90, 60, 10, 90,\n",
       "                    40, 40, 50, 10, 10, 40, 50, 60, 70, 30, 20, 60, 30, 80,\n",
       "                    90, 90, 30, 90, 60, 40, 30, 70, 50, 90, 20, 10, 90, 50,\n",
       "                    60, 90, 60, 60, 60, 60, 10, 10, 20, 10, 20, 30, 50, 80,\n",
       "                    70, 20, 50, 40, 50, 90, 60, 50, 50, 40, 10, 60, 20, 30,\n",
       "                    60, 70, 70, 80, 70, 50, 50, 20, 10, 30, 70, 10, 60, 10,\n",
       "                    50, 40, 50, 30, 80, 40, 50, 30, 40, 70, 40, 60, 70, 30,\n",
       "                    70, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[6, 12, 6, 12, 3, 6, 3, 9, 3, 3, 9, 3, 12, 12, 3, 12, 6,\n",
       "                    12, 9, 9, 9, 12, 12, 9, 12, 12, 6, 12, 3, 3, 12, 12, 9,\n",
       "                    9, 3, 6, 9, 12, 6, 12, 9, 6, 9, 6, 3, 9, 6, 6, 12, 6,\n",
       "                    6, 9, 12, 3, 3, 3, 6, 6, 12, 6, 3, 3, 9, 9, 3, 12, 3,\n",
       "                    3, 12, 3, 9, 3, 6, 6, 9, 9, 6, 3, 3, 9, 3, 6, 6, 9, 6,\n",
       "                    9, 6, 3, 9, 6, 9, 12, 3, 3, 9, 3, 6, 9, 12, 12],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.01, 0.01, 0.001, 0.1, 0.001, 0.1,\n",
       "                    0.001, 0.01, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.1, 0.1, 0.01, 0.01, 0.1, 0.1, 0.1,\n",
       "                    0.001, 0.1, 0.01, 0.001, 0.01, 0.1, 0.1, 0.01, 0.1,\n",
       "                    0.01, 0.1, 0.1, 0.01, 0.001, 0.1, 0.01, 0.1, 0.001,\n",
       "                    0.01, 0.001, 0.01, 0.1, 0.001, 0.1, 0.001, 0.1, 0.001,\n",
       "                    0.1, 0.001, 0.001, 0.1, 0.001, 0.01, 0.1, 0.01, 0.01,\n",
       "                    0.001, 0.01, 0.001, 0.01, 0.1, 0.001, 0.001, 0.001,\n",
       "                    0.1, 0.001, 0.001, 0.001, 0.1, 0.01, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.1, 0.01, 0.1, 0.1, 0.001,\n",
       "                    0.01, 0.1, 0.1, 0.01, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.001, 0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_colsample_bytree': masked_array(data=[0.75, 0.5, 0.5, 0.75, 0.25, 0.25, 1.0, 1.0, 0.5, 1.0,\n",
       "                    0.75, 1.0, 0.75, 1.0, 1.0, 0.5, 1.0, 0.25, 0.25, 0.25,\n",
       "                    0.75, 0.5, 0.5, 0.25, 0.25, 0.25, 1.0, 0.75, 0.75,\n",
       "                    0.25, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 0.25, 0.5, 0.25,\n",
       "                    0.25, 0.25, 1.0, 0.5, 0.25, 0.75, 0.5, 1.0, 1.0, 0.5,\n",
       "                    0.75, 0.75, 0.75, 0.25, 0.25, 1.0, 0.75, 0.5, 0.25,\n",
       "                    1.0, 0.75, 0.75, 0.25, 0.75, 0.75, 0.75, 0.5, 0.5,\n",
       "                    0.75, 1.0, 0.25, 0.25, 0.25, 0.25, 0.5, 0.75, 0.75,\n",
       "                    0.75, 1.0, 0.75, 0.25, 0.75, 0.25, 0.75, 1.0, 0.25,\n",
       "                    1.0, 0.25, 0.25, 0.25, 0.5, 1.0, 0.75, 0.75, 0.75,\n",
       "                    0.75, 0.75, 0.5, 1.0, 0.75, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'subsample': 0.25,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0}],\n",
       " 'split0_test_score': array([-0.40242175, -0.30345333, -0.41546296, -0.50812255, -0.65910059,\n",
       "        -0.67133695, -0.48566771, -0.65862854, -0.48446322, -0.68380695,\n",
       "        -0.48611657, -0.47882692, -0.43181305, -0.24371091, -0.5003485 ,\n",
       "        -0.54696141, -0.56324909, -0.66148299, -0.66181807, -0.6045194 ,\n",
       "        -0.5480676 , -0.28266114, -0.2832009 , -0.62466031, -0.63359721,\n",
       "        -0.34114163, -0.44815103, -0.25595542, -0.66879287, -0.49118764,\n",
       "        -0.58963892, -0.65975846, -0.4887611 , -0.35353511, -0.49493281,\n",
       "        -0.54819815, -0.40216133, -0.44232206, -0.51508166, -0.47455078,\n",
       "        -0.55149762, -0.67444755, -0.35650089, -0.56778929, -0.48867756,\n",
       "        -0.67335227, -0.53254569, -0.67188211, -0.64598384, -0.52066805,\n",
       "        -0.68625871, -0.44310668, -0.68523824, -0.53061676, -0.67890211,\n",
       "        -0.48951575, -0.67467571, -0.68849963, -0.29072553, -0.68034518,\n",
       "        -0.5989071 , -0.49469385, -0.50355114, -0.52281494, -0.67968887,\n",
       "        -0.5565448 , -0.69087389, -0.57959137, -0.35218936, -0.68764814,\n",
       "        -0.67719084, -0.68024571, -0.44633293, -0.66786586, -0.66358407,\n",
       "        -0.66897312, -0.43592346, -0.64273244, -0.69010819, -0.68516877,\n",
       "        -0.67383704, -0.66878723, -0.55619055, -0.6505865 , -0.46678266,\n",
       "        -0.56874121, -0.46229626, -0.53280899, -0.67209917, -0.60595142,\n",
       "        -0.35972664, -0.32029253, -0.61185249, -0.67501327, -0.67677682,\n",
       "        -0.6774396 , -0.56469675, -0.57851655, -0.65462128, -0.63447307]),\n",
       " 'split1_test_score': array([-0.41191415, -0.3084243 , -0.42201954, -0.51131724, -0.65927484,\n",
       "        -0.67306487, -0.49765316, -0.6584223 , -0.49217507, -0.68398905,\n",
       "        -0.48972083, -0.49345246, -0.427048  , -0.251588  , -0.50823351,\n",
       "        -0.54567188, -0.56520098, -0.66529621, -0.66506038, -0.60943672,\n",
       "        -0.55053301, -0.28886831, -0.28799584, -0.62531317, -0.63892167,\n",
       "        -0.33728758, -0.45611421, -0.25226355, -0.67082864, -0.49997596,\n",
       "        -0.58547037, -0.66130443, -0.49210222, -0.35880054, -0.49773039,\n",
       "        -0.5496864 , -0.40327849, -0.45169166, -0.53523927, -0.50123011,\n",
       "        -0.55402726, -0.67462681, -0.35928425, -0.5789939 , -0.49696699,\n",
       "        -0.67343461, -0.53737004, -0.67217398, -0.64498302, -0.52519278,\n",
       "        -0.68667875, -0.45456971, -0.68572333, -0.54120458, -0.67887716,\n",
       "        -0.49757583, -0.67487898, -0.68853514, -0.29135218, -0.68041863,\n",
       "        -0.60113403, -0.50195057, -0.50831129, -0.5276413 , -0.68054392,\n",
       "        -0.55572292, -0.69104134, -0.58859001, -0.35307587, -0.68774584,\n",
       "        -0.6777455 , -0.68112051, -0.45611967, -0.66951884, -0.6645744 ,\n",
       "        -0.66984885, -0.4444625 , -0.64359189, -0.69060805, -0.68545999,\n",
       "        -0.67556372, -0.67147112, -0.56232515, -0.65045652, -0.4685282 ,\n",
       "        -0.5689759 , -0.47031153, -0.54446868, -0.67355589, -0.60724426,\n",
       "        -0.36248011, -0.321334  , -0.61766221, -0.67512225, -0.67737238,\n",
       "        -0.67750221, -0.5722574 , -0.57694664, -0.65573971, -0.63566119]),\n",
       " 'split2_test_score': array([-0.39711959, -0.30282984, -0.40963791, -0.50866189, -0.65724873,\n",
       "        -0.67235735, -0.48368129, -0.65800435, -0.479623  , -0.68343336,\n",
       "        -0.48464644, -0.47876415, -0.43018289, -0.25544256, -0.49452288,\n",
       "        -0.541461  , -0.55972178, -0.66358332, -0.66422268, -0.60477534,\n",
       "        -0.54641579, -0.29024265, -0.2794847 , -0.62349802, -0.63675414,\n",
       "        -0.32906647, -0.44336831, -0.25275136, -0.66963176, -0.48839716,\n",
       "        -0.5827866 , -0.66062622, -0.48767457, -0.35836547, -0.4844399 ,\n",
       "        -0.54404423, -0.39886373, -0.44580164, -0.52398598, -0.50062492,\n",
       "        -0.54881075, -0.67404399, -0.35043405, -0.5731122 , -0.48469366,\n",
       "        -0.67294485, -0.53197237, -0.67146175, -0.64445332, -0.51638265,\n",
       "        -0.68642139, -0.44898502, -0.68544808, -0.53105324, -0.67848662,\n",
       "        -0.48367912, -0.67407352, -0.68833029, -0.29332182, -0.67998362,\n",
       "        -0.59647272, -0.48909082, -0.50471656, -0.5242257 , -0.67992684,\n",
       "        -0.55104024, -0.69092578, -0.58266635, -0.34979317, -0.68732529,\n",
       "        -0.67720858, -0.68035637, -0.44218508, -0.66868278, -0.66382797,\n",
       "        -0.66929162, -0.43374675, -0.64166748, -0.69043657, -0.68514488,\n",
       "        -0.67461617, -0.67075199, -0.55712834, -0.64953117, -0.45791981,\n",
       "        -0.56472248, -0.45894297, -0.53131124, -0.67284766, -0.60341498,\n",
       "        -0.35375873, -0.31867534, -0.61326894, -0.67449951, -0.67689256,\n",
       "        -0.67696737, -0.56613184, -0.57536788, -0.65505449, -0.63461586]),\n",
       " 'split3_test_score': array([-0.41335071, -0.31569859, -0.42729443, -0.5155792 , -0.65941271,\n",
       "        -0.6742307 , -0.4954945 , -0.65900377, -0.49354729, -0.68410962,\n",
       "        -0.49245316, -0.48771286, -0.42889843, -0.25496202, -0.50716121,\n",
       "        -0.54589126, -0.56610846, -0.66479347, -0.66526117, -0.61405641,\n",
       "        -0.55353202, -0.29382061, -0.29698547, -0.62656242, -0.64181014,\n",
       "        -0.3750055 , -0.46092547, -0.25468337, -0.67031002, -0.51167996,\n",
       "        -0.59159662, -0.66285981, -0.49265885, -0.36680449, -0.50529832,\n",
       "        -0.55000767, -0.44793164, -0.45154378, -0.55383026, -0.49964948,\n",
       "        -0.55658527, -0.67479283, -0.36966186, -0.58700746, -0.49905374,\n",
       "        -0.67372222, -0.53719368, -0.67219831, -0.64791092, -0.52646304,\n",
       "        -0.6867913 , -0.46843669, -0.68608282, -0.57227696, -0.679003  ,\n",
       "        -0.49742244, -0.67499524, -0.68854245, -0.30054802, -0.68044372,\n",
       "        -0.60155085, -0.50384938, -0.50927015, -0.53110006, -0.68069519,\n",
       "        -0.55841076, -0.69090042, -0.58790396, -0.35195179, -0.68835756,\n",
       "        -0.67937971, -0.68195298, -0.47112846, -0.66930471, -0.66461045,\n",
       "        -0.67033309, -0.45083742, -0.6439862 , -0.69062726, -0.68616418,\n",
       "        -0.67509217, -0.67168573, -0.56229295, -0.65122947, -0.50515765,\n",
       "        -0.56737725, -0.47343265, -0.57517706, -0.67528464, -0.60809448,\n",
       "        -0.36724092, -0.33344186, -0.61687858, -0.67517004, -0.67758423,\n",
       "        -0.67752851, -0.56944158, -0.57990306, -0.6555947 , -0.63551887]),\n",
       " 'split4_test_score': array([-0.40645646, -0.30629807, -0.4214681 , -0.51419564, -0.65952855,\n",
       "        -0.67387466, -0.49782274, -0.65960687, -0.49344875, -0.68429635,\n",
       "        -0.49208422, -0.49275713, -0.43311633, -0.25058954, -0.50995101,\n",
       "        -0.54397345, -0.56854353, -0.6634081 , -0.66325001, -0.61254765,\n",
       "        -0.55382286, -0.28743763, -0.2871209 , -0.62570031, -0.63963046,\n",
       "        -0.36851028, -0.45873312, -0.25350078, -0.67071266, -0.51022948,\n",
       "        -0.59002891, -0.66204873, -0.49399132, -0.36047645, -0.50367855,\n",
       "        -0.5544205 , -0.4382507 , -0.44748232, -0.54912161, -0.48986516,\n",
       "        -0.55269787, -0.67518118, -0.36845749, -0.58407804, -0.50019686,\n",
       "        -0.67346356, -0.54072686, -0.67283451, -0.64647613, -0.52827176,\n",
       "        -0.68684583, -0.46235209, -0.68584292, -0.56751186, -0.67958925,\n",
       "        -0.49905435, -0.67497731, -0.68856957, -0.28973002, -0.68073919,\n",
       "        -0.60333963, -0.5034499 , -0.50957907, -0.53131101, -0.68098027,\n",
       "        -0.55652032, -0.69091953, -0.58938807, -0.35113761, -0.68823086,\n",
       "        -0.67881386, -0.681795  , -0.46727039, -0.66929505, -0.66470351,\n",
       "        -0.67018501, -0.44689288, -0.64552794, -0.69060851, -0.68583892,\n",
       "        -0.67539349, -0.67090118, -0.56306098, -0.65209047, -0.50124529,\n",
       "        -0.57115992, -0.47089522, -0.56991133, -0.67454672, -0.60796801,\n",
       "        -0.36516717, -0.32257304, -0.61802348, -0.67574631, -0.67765665,\n",
       "        -0.67804607, -0.56894681, -0.58086344, -0.65563767, -0.63513042]),\n",
       " 'mean_test_score': array([-0.40625232, -0.30734061, -0.41917632, -0.51157511, -0.65891307,\n",
       "        -0.67297284, -0.49206359, -0.65873314, -0.48865121, -0.68392705,\n",
       "        -0.48900407, -0.48630241, -0.43021174, -0.25125841, -0.50404318,\n",
       "        -0.54479183, -0.56456464, -0.66371276, -0.66392241, -0.60906686,\n",
       "        -0.55047409, -0.28860588, -0.2869573 , -0.6251468 , -0.63814254,\n",
       "        -0.35020131, -0.45345809, -0.25383093, -0.67005515, -0.50029347,\n",
       "        -0.58790421, -0.66131946, -0.49103748, -0.35959614, -0.49721568,\n",
       "        -0.54927126, -0.41809594, -0.44776812, -0.53545077, -0.49318368,\n",
       "        -0.55272366, -0.67461846, -0.36086732, -0.5781957 , -0.49391745,\n",
       "        -0.67338349, -0.53596155, -0.67211011, -0.6459614 , -0.52339546,\n",
       "        -0.68659918, -0.45548943, -0.68566706, -0.54853154, -0.67897162,\n",
       "        -0.49344925, -0.67472014, -0.68849541, -0.29313539, -0.68038606,\n",
       "        -0.60028076, -0.49860664, -0.50708549, -0.52741837, -0.68036699,\n",
       "        -0.55564776, -0.69093219, -0.58562772, -0.35162957, -0.68786152,\n",
       "        -0.67806764, -0.68109407, -0.45660664, -0.66893341, -0.66426005,\n",
       "        -0.6697263 , -0.44237224, -0.64350113, -0.6904777 , -0.68555532,\n",
       "        -0.67490048, -0.67071939, -0.56019943, -0.65077879, -0.4799256 ,\n",
       "        -0.56819532, -0.46717545, -0.5507343 , -0.67366674, -0.60653456,\n",
       "        -0.36167451, -0.32326312, -0.615537  , -0.67511026, -0.67725651,\n",
       "        -0.67749674, -0.56829478, -0.57831944, -0.65532955, -0.63507986]),\n",
       " 'std_test_score': array([6.00941223e-03, 4.63835961e-03, 6.06643649e-03, 2.94527475e-03,\n",
       "        8.44340255e-04, 1.04489912e-03, 6.12136568e-03, 5.43193645e-04,\n",
       "        5.62945349e-03, 2.93840407e-04, 3.13762747e-03, 6.44188132e-03,\n",
       "        2.13238666e-03, 4.21308351e-03, 5.77010298e-03, 1.92120343e-03,\n",
       "        2.95983304e-03, 1.32341876e-03, 1.26949951e-03, 3.90498956e-03,\n",
       "        2.92674301e-03, 3.65096882e-03, 5.85858189e-03, 1.02889312e-03,\n",
       "        2.78787081e-03, 1.81435341e-02, 6.64244139e-03, 1.33953332e-03,\n",
       "        7.57409723e-04, 9.51746206e-03, 3.26406289e-03, 1.07908534e-03,\n",
       "        2.40743383e-03, 4.28063514e-03, 7.42684622e-03, 3.33770422e-03,\n",
       "        2.06865766e-02, 3.55698429e-03, 1.46362159e-02, 1.01995957e-02,\n",
       "        2.58555571e-03, 3.75857865e-04, 7.28523919e-03, 7.02888047e-03,\n",
       "        6.12612329e-03, 2.51848959e-04, 3.27998799e-03, 4.49209573e-04,\n",
       "        1.20808716e-03, 4.31361513e-03, 2.24324871e-04, 9.06879555e-03,\n",
       "        2.96239919e-04, 1.79119273e-02, 3.55361891e-04, 5.91878607e-03,\n",
       "        3.42675172e-04, 8.55266621e-05, 3.88745059e-03, 2.41954885e-04,\n",
       "        2.37004726e-03, 5.79630669e-03, 2.47376175e-03, 3.46820886e-03,\n",
       "        4.83473722e-04, 2.46718210e-03, 5.74886708e-05, 3.82901898e-03,\n",
       "        1.10666030e-03, 3.81813159e-04, 8.81911550e-04, 7.06207324e-04,\n",
       "        1.12991848e-02, 6.02324696e-04, 4.60851547e-04, 5.19590497e-04,\n",
       "        6.51843293e-03, 1.28875466e-03, 1.97337254e-04, 3.94484965e-04,\n",
       "        6.21537751e-04, 1.02631566e-03, 2.91869495e-03, 8.50986396e-04,\n",
       "        1.93805449e-02, 2.11780771e-03, 5.55705833e-03, 1.84553977e-02,\n",
       "        1.14301814e-03, 1.73571716e-03, 4.69648143e-03, 5.24728920e-03,\n",
       "        2.49879123e-03, 3.97661873e-04, 3.58750591e-04, 3.42428418e-04,\n",
       "        2.64833950e-03, 1.98062773e-03, 4.26810996e-04, 4.72600792e-04]),\n",
       " 'rank_test_score': array([ 13,   6,  15,  37,  69,  79,  28,  68,  25,  93,  26,  24,  16,\n",
       "          1,  35,  42,  50,  71,  72,  59,  45,   4,   3,  61,  63,   8,\n",
       "         19,   2,  76,  34,  56,  70,  27,  10,  32,  44,  14,  18,  40,\n",
       "         29,  47,  82,  11,  53,  31,  80,  41,  78,  65,  38,  96,  20,\n",
       "         95,  43,  89,  30,  83,  98,   5,  91,  57,  33,  36,  39,  90,\n",
       "         48, 100,  55,   9,  97,  88,  92,  21,  74,  73,  75,  17,  64,\n",
       "         99,  94,  84,  77,  49,  66,  23,  51,  22,  46,  81,  58,  12,\n",
       "          7,  60,  85,  86,  87,  52,  54,  67,  62], dtype=int32)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.952\n",
      "ROC AUC Teste: 0.691\n",
      "Lucro Relativo: 0.762\n",
      "Lucro Relativo Teste: 0.215\n",
      "Lucro Total: 144460.00\n",
      "Lucro Total Teste: 40765.81\n",
      "F1: 0.491\n",
      "F1 Teste: 0.249\n",
      "Log Loss: 2.796\n",
      "Log Loss Teste: 3.956\n"
     ]
    }
   ],
   "source": [
    "\n",
    "XGB = XGBClassifier(\n",
    "   scale_pos_weight = sum(y_train == 0) / sum(y_train == 1),\n",
    "   n_estimators = 90, #30 40 60 40\n",
    "   max_depth = 12, #6 9 12 12\n",
    "   learning_rate = 0.1, #0.01 0.1 0.01 0.001\n",
    "   colsample_bytree = 1,\n",
    "   subsample = 0.75, #0.25 0.25 0.25 0.5\n",
    "   random_state = 42\n",
    ")\n",
    "XGB.fit(x_train,y_train)\n",
    "y_p_train = XGB.predict(x_train)\n",
    "y_p_test = XGB.predict(x_test)\n",
    "\n",
    "auc = roc_auc_score(y_train, y_p_train)\n",
    "auc_test = roc_auc_score(y_test, y_p_test)\n",
    "print('ROC AUC: %.3f' % auc)\n",
    "print('ROC AUC Teste: %.3f' % auc_test)\n",
    "\n",
    "LR = funcao_lucro(y_train, y_p_train)\n",
    "LR_test = funcao_lucro(y_test, y_p_test)\n",
    "print('Lucro Relativo: %.3f' % LR)\n",
    "print('Lucro Relativo Teste: %.3f' % LR_test)\n",
    "print('Lucro Total: %.2f' % (LR*LM))\n",
    "print('Lucro Total Teste: %.2f' % (LR_test*LM))\n",
    "\n",
    "F1 = f1_score(y_train, y_p_train)\n",
    "F1_test = f1_score(y_test, y_p_test)\n",
    "print('F1: %.3f' % F1)\n",
    "print('F1 Teste: %.3f' % F1_test)\n",
    "\n",
    "LL = log_loss(y_train, y_p_train)\n",
    "LL_test = log_loss(y_test, y_p_test)\n",
    "print('Log Loss: %.3f' % LL)\n",
    "print('Log Loss Teste: %.3f' % LL_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Lucro Relativo: 0.239\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(XGB, x_train, y_train, scoring=lucro, cv=10) #para classificacao o cv ja eh estratificado pela target\n",
    "\n",
    "print('Media Lucro Relativo: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC AUC: 0.768\n",
    "ROC AUC Teste: 0.759\n",
    "Lucro Relativo: 0.208\n",
    "Lucro Relativo Teste: 0.180\n",
    "Lucro Total: 39400.00\n",
    "Lucro Total Teste: 34181.64\n",
    "F1: 0.227\n",
    "F1 Teste: 0.219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var15                       0.121741\n",
       "saldo_var30                 0.076560\n",
       "saldo_var42                 0.062785\n",
       "saldo_var5                  0.050800\n",
       "saldo_medio_var5_ult1       0.049382\n",
       "                              ...   \n",
       "ind_var7_emit_ult1          0.000000\n",
       "num_var17_0                 0.000000\n",
       "num_var18_0                 0.000000\n",
       "num_var20                   0.000000\n",
       "imp_trasp_var17_in_hace3    0.000000\n",
       "Length: 268, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "XGB.fit(x_train,y_train)\n",
    "\n",
    "feature_scores = pd.Series(XGB.feature_importances_, index=x_train.columns).sort_values(ascending=False)\n",
    "\n",
    "feature_scores.to_csv('feature_importance_XGB.csv',header=False)\n",
    "\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_grid_param = {\n",
    "    'n_estimators': range(10,100,10),\n",
    "    'max_depth': range(3,13,3), #default 6\n",
    "    'learning_rate': [0.001,0.01,0.1], #default 0,3\n",
    "    'subsample': np.arange(0.25,1.01,0.25), #default 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-9203e392e421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "n_col = [5,10,15,20,30,40,50,70,100]\n",
    "n_col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-e7c16c65000d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subsample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "a = np.array(['x','y'])\n",
    "\n",
    "b = np.append(a,['z'])\n",
    "a = a.append(random_search.best_params_['subsample'])\n",
    "a = a.append(random_search.best_params_['learning_rate'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_col = [5,10,15,20,30,40,50,70,100]\n",
    "n_est = []\n",
    "max_dp = []\n",
    "l_rate = []\n",
    "subsp = []\n",
    "i = 0\n",
    "\n",
    "for n in n_col:\n",
    "    \n",
    "    x_train_sample = x_train[x_train.columns[:n]]\n",
    "\n",
    "    random_search = RandomizedSearchCV(estimator=XGB, \n",
    "                            param_distributions=XGB_grid_param,\n",
    "                            n_iter=100,\n",
    "                            scoring=lucro, \n",
    "                            n_jobs=-1, \n",
    "                            cv=5)\n",
    "\n",
    "    random_search.fit(x_train_sample,y_train)\n",
    "\n",
    "    n_est[i] = random_search.best_params_['subsample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.25,\n",
       " 'n_estimators': 60,\n",
       " 'max_depth': 12,\n",
       " 'learning_rate': 0.01,\n",
       " 'colsample_bytree': 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03773925423120555 {'subsample': 0.75, 'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.24109661702541016 {'subsample': 0.5, 'n_estimators': 40, 'max_depth': 12, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.173361437853375 {'subsample': 0.25, 'n_estimators': 40, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "-0.02893338471668587 {'subsample': 0.75, 'n_estimators': 40, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.21028042287561385 {'subsample': 1.0, 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.07666069800855917 {'subsample': 0.5, 'n_estimators': 20, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.21545424530977197 {'subsample': 0.5, 'n_estimators': 80, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.128028590288347 {'subsample': 1.0, 'n_estimators': 20, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.21260243845673554 {'subsample': 0.25, 'n_estimators': 70, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "-0.08500351123146906 {'subsample': 1.0, 'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.21978680173135545 {'subsample': 0.25, 'n_estimators': 40, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.10867765247218539 {'subsample': 0.5, 'n_estimators': 40, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.19719983346957162 {'subsample': 0.75, 'n_estimators': 30, 'max_depth': 9, 'learning_rate': 0.001, 'colsample_bytree': 0.5}\n",
      "0.21312835893534907 {'subsample': 0.75, 'n_estimators': 70, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "-0.024450035231684347 {'subsample': 1.0, 'n_estimators': 40, 'max_depth': 12, 'learning_rate': 0.001, 'colsample_bytree': 0.25}\n",
      "0.10419566086872299 {'subsample': 0.5, 'n_estimators': 20, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.21144236062075714 {'subsample': 0.75, 'n_estimators': 80, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.20681199411550494 {'subsample': 0.25, 'n_estimators': 20, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "-0.006413761963606319 {'subsample': 0.5, 'n_estimators': 90, 'max_depth': 12, 'learning_rate': 0.001, 'colsample_bytree': 0.25}\n",
      "0.12376444296981363 {'subsample': 0.5, 'n_estimators': 70, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.00034723991926603656 {'subsample': 0.5, 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.001, 'colsample_bytree': 0.25}\n",
      "0.21730445663039857 {'subsample': 0.5, 'n_estimators': 30, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.2090108946963192 {'subsample': 0.5, 'n_estimators': 70, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.22605588759770376 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.13153195547483676 {'subsample': 1.0, 'n_estimators': 70, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.13477835456088513 {'subsample': 0.75, 'n_estimators': 10, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.23623974763374844 {'subsample': 0.25, 'n_estimators': 30, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.2120743670960205 {'subsample': 1.0, 'n_estimators': 90, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.1793158158158495 {'subsample': 0.75, 'n_estimators': 40, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "-0.005127282465891538 {'subsample': 1.0, 'n_estimators': 60, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.1681343153544471 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.04261159692381809 {'subsample': 1.0, 'n_estimators': 60, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.12298301673219204 {'subsample': 0.75, 'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.19867777196077768 {'subsample': 0.25, 'n_estimators': 10, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "-0.055646102741796995 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.18501447583636915 {'subsample': 0.5, 'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.11031120819779128 {'subsample': 1.0, 'n_estimators': 60, 'max_depth': 9, 'learning_rate': 0.001, 'colsample_bytree': 0.5}\n",
      "0.18442816614485177 {'subsample': 0.75, 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.17930279374857802 {'subsample': 1.0, 'n_estimators': 80, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.11680479598567754 {'subsample': 1.0, 'n_estimators': 20, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.18053167139381476 {'subsample': 0.75, 'n_estimators': 90, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.2213076457910016 {'subsample': 0.25, 'n_estimators': 10, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.2177768632159199 {'subsample': 0.25, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 0.75}\n",
      "0.21835350416281524 {'subsample': 0.5, 'n_estimators': 60, 'max_depth': 9, 'learning_rate': 0.001, 'colsample_bytree': 0.5}\n",
      "0.15831787696917457 {'subsample': 0.25, 'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.18343247050653877 {'subsample': 0.5, 'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "0.2235231196299151 {'subsample': 0.5, 'n_estimators': 40, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.1835994207360516 {'subsample': 0.75, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.12025919201825541 {'subsample': 0.75, 'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.001, 'colsample_bytree': 0.75}\n",
      "0.1996363478532021 {'subsample': 0.5, 'n_estimators': 20, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.21435002456989907 {'subsample': 0.5, 'n_estimators': 20, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.01884893811477406 {'subsample': 0.75, 'n_estimators': 10, 'max_depth': 3, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.015264261917398225 {'subsample': 0.25, 'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.001, 'colsample_bytree': 0.25}\n",
      "0.19555654948375478 {'subsample': 0.75, 'n_estimators': 90, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.23682099727792746 {'subsample': 0.5, 'n_estimators': 30, 'max_depth': 12, 'learning_rate': 0.001, 'colsample_bytree': 0.75}\n",
      "0.209488536561689 {'subsample': 0.25, 'n_estimators': 20, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.13500781392883507 {'subsample': 0.75, 'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "-0.019457484565012916 {'subsample': 0.25, 'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.19883086963139662 {'subsample': 0.5, 'n_estimators': 90, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.16428629924732602 {'subsample': 0.75, 'n_estimators': 60, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.2216268565945027 {'subsample': 1.0, 'n_estimators': 30, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.14026877449536035 {'subsample': 1.0, 'n_estimators': 70, 'max_depth': 12, 'learning_rate': 0.001, 'colsample_bytree': 0.5}\n",
      "0.22485164552789982 {'subsample': 0.5, 'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.23830407681596616 {'subsample': 0.5, 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "-0.05256691787403685 {'subsample': 1.0, 'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.20917014245216 {'subsample': 0.25, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 0.5}\n",
      "0.20105526989194072 {'subsample': 0.25, 'n_estimators': 20, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.1196463808012611 {'subsample': 1.0, 'n_estimators': 40, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.20185392737339658 {'subsample': 0.25, 'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.14861723189748088 {'subsample': 1.0, 'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.18381696523353147 {'subsample': 0.25, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.17815707710412748 {'subsample': 0.25, 'n_estimators': 20, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.09360094624705484 {'subsample': 0.5, 'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "-0.06496895865054998 {'subsample': 0.5, 'n_estimators': 40, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.14023885848626935 {'subsample': 1.0, 'n_estimators': 30, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "0.17034385239583766 {'subsample': 0.5, 'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.1716546328700877 {'subsample': 0.5, 'n_estimators': 10, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 0.5}\n",
      "0.16128044024123786 {'subsample': 1.0, 'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.001, 'colsample_bytree': 0.75}\n",
      "0.2221608008416481 {'subsample': 0.5, 'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.20221186214057024 {'subsample': 1.0, 'n_estimators': 50, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.2143501309316842 {'subsample': 0.5, 'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.21386648833419364 {'subsample': 0.75, 'n_estimators': 60, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.20111324040259285 {'subsample': 0.25, 'n_estimators': 60, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.21424626304248515 {'subsample': 0.75, 'n_estimators': 80, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.1189986657598298 {'subsample': 0.75, 'n_estimators': 40, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.20954224002556504 {'subsample': 0.75, 'n_estimators': 60, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.2164999317862736 {'subsample': 0.75, 'n_estimators': 60, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "-0.03812942021559154 {'subsample': 0.25, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.14337901608766604 {'subsample': 1.0, 'n_estimators': 20, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "0.2111732321148271 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.164282286810684 {'subsample': 1.0, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.21925446609749769 {'subsample': 0.5, 'n_estimators': 90, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "-0.05267120075048812 {'subsample': 1.0, 'n_estimators': 10, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "0.12994280535966893 {'subsample': 0.25, 'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "-0.07519671785039798 {'subsample': 1.0, 'n_estimators': 20, 'max_depth': 3, 'learning_rate': 0.001, 'colsample_bytree': 0.5}\n",
      "0.20427644151391303 {'subsample': 1.0, 'n_estimators': 30, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.013212332098272647 {'subsample': 0.75, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.211541437951649 {'subsample': 0.75, 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.2073801913704892 {'subsample': 0.75, 'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.1563726398672286 {'subsample': 0.75, 'n_estimators': 10, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "cvres = random_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'],cvres['params']):\n",
    "    print(mean_score,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 4.33855481,  7.01745782, 11.43931851,  1.36729298,  1.98947186,\n",
       "         9.68526158,  1.61715202, 19.5656261 ,  6.30104685, 11.9486001 ,\n",
       "         2.64885592,  7.96334801,  6.3558681 ,  4.22727823,  4.46220798,\n",
       "         0.76929431,  0.64557896,  1.70019608,  3.19084687,  3.55785933,\n",
       "         3.45822229,  3.70062704,  1.25550461,  0.80436006,  2.35637555,\n",
       "         2.59620304,  0.87908049,  3.96140661, 14.38854384,  0.65423627,\n",
       "        16.18291926,  3.83336215,  6.69907036, 13.36901145,  5.63899488,\n",
       "         0.92601681,  0.50508542,  6.67481055,  7.5546946 ,  4.96213465,\n",
       "         1.87533169,  3.35573759,  1.8562788 ,  4.322118  ,  0.69895673,\n",
       "         4.57275319,  7.98207598,  1.0717247 ,  5.12769585,  1.96209564,\n",
       "        12.77641258,  2.48255925, 11.10846157,  9.1010705 , 13.47545323,\n",
       "         8.0668541 , 12.49923882,  4.74128838, 12.70325933,  1.77395134,\n",
       "        19.57843223,  1.63026342,  0.88979816,  8.50941133,  1.7502008 ,\n",
       "        18.79781518,  4.16441989,  2.4832242 , 22.91902561,  2.60815625,\n",
       "         6.01522298,  9.47924008,  1.20742669,  6.99261961, 14.6176199 ,\n",
       "         1.68537917, 10.96890454, 15.49194613,  4.62677126,  5.36601071,\n",
       "         3.24903646,  3.05028286,  5.73649979, 13.20229988,  1.44025946,\n",
       "         4.26900315,  2.0367805 , 11.92068644, 12.81985197,  1.95171118,\n",
       "         6.7485136 ,  5.34258223,  3.43984914,  5.00669322, 14.31644049,\n",
       "         0.62422924,  1.43862243,  2.49251122,  9.38836093, 11.80643244]),\n",
       " 'std_fit_time': array([0.22797305, 0.45750216, 0.20550493, 0.0813618 , 0.02640154,\n",
       "        0.07757312, 0.04508869, 0.15845211, 0.19809699, 0.20070464,\n",
       "        0.02735338, 0.16199366, 0.18437588, 0.02521565, 0.04520034,\n",
       "        0.03687644, 0.01556586, 0.01106296, 0.0555127 , 0.07591265,\n",
       "        0.10941409, 0.22574071, 0.01876764, 0.04251956, 0.04625845,\n",
       "        0.08547249, 0.01561562, 0.1022972 , 0.11407278, 0.01039105,\n",
       "        0.13998189, 0.0324567 , 0.48187229, 0.4106116 , 0.14612919,\n",
       "        0.03449487, 0.00826794, 0.09620653, 0.10626983, 0.06234752,\n",
       "        0.04879456, 0.11451813, 0.04105798, 0.09989403, 0.01528503,\n",
       "        0.15441532, 0.1133458 , 0.03783234, 0.04411435, 0.02089306,\n",
       "        0.11846453, 0.03473236, 0.16679601, 0.32848549, 0.37036178,\n",
       "        0.03910186, 0.09924021, 0.05281252, 0.14458049, 0.06247224,\n",
       "        0.21334378, 0.13611238, 0.01539155, 0.10938704, 0.03587342,\n",
       "        0.12225627, 0.08449346, 0.07777757, 0.17374434, 0.06475249,\n",
       "        0.04288354, 0.15778219, 0.04019891, 0.0420235 , 0.2002129 ,\n",
       "        0.18612264, 0.23494768, 0.24405898, 0.22097068, 0.20702559,\n",
       "        0.06451238, 0.04666976, 0.15662357, 0.19758432, 0.0268457 ,\n",
       "        0.04152705, 0.07584905, 0.17896852, 0.13058394, 0.12893982,\n",
       "        0.25391662, 0.19584385, 0.09504547, 0.09656313, 0.1785257 ,\n",
       "        0.03595818, 0.03825227, 0.04827875, 0.51028422, 2.52763934]),\n",
       " 'mean_score_time': array([0.08041444, 0.09627361, 0.1671361 , 0.05738897, 0.05923305,\n",
       "        0.09627237, 0.06006374, 0.18508639, 0.10721974, 0.09471369,\n",
       "        0.05988336, 0.21766162, 0.13895416, 0.07145619, 0.07842307,\n",
       "        0.05690823, 0.056248  , 0.05908046, 0.06079292, 0.09942341,\n",
       "        0.0643342 , 0.09585662, 0.06047964, 0.05809636, 0.06153011,\n",
       "        0.07182264, 0.05963855, 0.06846366, 0.14286962, 0.0521925 ,\n",
       "        0.1681149 , 0.10006638, 0.11478877, 0.13120813, 0.07575202,\n",
       "        0.05271411, 0.04887576, 0.08973942, 0.10122976, 0.0742414 ,\n",
       "        0.06991234, 0.06353288, 0.0653645 , 0.11819205, 0.05585828,\n",
       "        0.06722112, 0.14161983, 0.05856729, 0.08045797, 0.06568694,\n",
       "        0.12362156, 0.0620604 , 0.1292532 , 0.07776961, 0.10070658,\n",
       "        0.10290132, 0.09520288, 0.08414049, 0.11336384, 0.05347514,\n",
       "        0.16574631, 0.06085467, 0.05298629, 0.10558476, 0.05807939,\n",
       "        0.20157266, 0.08596735, 0.05143757, 0.19489837, 0.0572166 ,\n",
       "        0.09481859, 0.12652006, 0.05807681, 0.08030372, 0.10766406,\n",
       "        0.06758766, 0.11499977, 0.21777587, 0.11504173, 0.13196306,\n",
       "        0.09482946, 0.08453698, 0.07840676, 0.10728731, 0.06086822,\n",
       "        0.10204053, 0.06776671, 0.13673534, 0.17580805, 0.06843467,\n",
       "        0.15753474, 0.13276467, 0.09082394, 0.08681459, 0.13253255,\n",
       "        0.05127707, 0.05706725, 0.07154236, 0.13342285, 0.11320419]),\n",
       " 'std_score_time': array([0.00619942, 0.01252254, 0.03313087, 0.00500849, 0.00386945,\n",
       "        0.00711488, 0.0036591 , 0.00845518, 0.00477722, 0.00704156,\n",
       "        0.00487832, 0.07155685, 0.00971894, 0.00404235, 0.00315371,\n",
       "        0.00670072, 0.00276756, 0.00253038, 0.00394085, 0.00529375,\n",
       "        0.00731647, 0.00345154, 0.00431971, 0.00501634, 0.00616122,\n",
       "        0.00285078, 0.00563989, 0.00517677, 0.00650862, 0.00227903,\n",
       "        0.03121192, 0.0034068 , 0.07235198, 0.00413944, 0.00675333,\n",
       "        0.00358651, 0.00404438, 0.00316261, 0.00669431, 0.00464995,\n",
       "        0.00469602, 0.00431147, 0.00208844, 0.00524249, 0.0047062 ,\n",
       "        0.00495104, 0.00772808, 0.01043767, 0.00521837, 0.00215393,\n",
       "        0.00620612, 0.0093356 , 0.01136731, 0.00481568, 0.00367814,\n",
       "        0.01627658, 0.0072569 , 0.00730214, 0.00427745, 0.00315039,\n",
       "        0.03899461, 0.01183281, 0.00564163, 0.00618866, 0.00612332,\n",
       "        0.01932835, 0.00304829, 0.00214621, 0.01015446, 0.00437664,\n",
       "        0.00281282, 0.0039009 , 0.00832778, 0.01017816, 0.00570573,\n",
       "        0.00686687, 0.00731284, 0.0073652 , 0.00450157, 0.0081252 ,\n",
       "        0.00342709, 0.00498003, 0.01956197, 0.00494703, 0.0040482 ,\n",
       "        0.00539041, 0.00186252, 0.01588595, 0.03416908, 0.00288356,\n",
       "        0.00374693, 0.00615029, 0.00598537, 0.0060185 , 0.0322243 ,\n",
       "        0.01229217, 0.0057959 , 0.00386323, 0.00703731, 0.02931523]),\n",
       " 'param_subsample': masked_array(data=[0.75, 1.0, 0.75, 0.25, 1.0, 0.75, 0.25, 1.0, 0.5, 0.5,\n",
       "                    0.75, 0.75, 0.75, 0.5, 1.0, 0.5, 1.0, 1.0, 0.75, 0.25,\n",
       "                    1.0, 0.5, 0.25, 0.25, 0.5, 0.5, 0.25, 0.5, 0.75, 0.5,\n",
       "                    1.0, 1.0, 0.75, 0.5, 0.75, 0.75, 0.5, 0.5, 0.25, 0.75,\n",
       "                    0.25, 1.0, 0.25, 0.25, 0.25, 0.5, 0.25, 1.0, 0.25,\n",
       "                    0.25, 0.75, 0.75, 0.25, 1.0, 1.0, 0.5, 0.75, 0.5, 0.75,\n",
       "                    0.5, 0.75, 0.25, 0.25, 0.5, 0.25, 1.0, 0.25, 0.75,\n",
       "                    0.75, 0.75, 0.25, 0.25, 0.5, 0.5, 1.0, 0.25, 1.0, 0.75,\n",
       "                    0.75, 0.75, 0.5, 0.75, 0.5, 1.0, 0.5, 0.5, 0.75, 0.25,\n",
       "                    0.25, 0.5, 0.5, 0.25, 0.75, 0.75, 1.0, 0.5, 1.0, 0.25,\n",
       "                    1.0, 0.75],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[40, 20, 90, 20, 40, 40, 30, 70, 40, 90, 60, 90, 90, 20,\n",
       "                    30, 10, 20, 60, 10, 90, 40, 40, 50, 10, 40, 90, 20, 70,\n",
       "                    60, 10, 80, 40, 20, 80, 30, 10, 10, 40, 40, 20, 20, 50,\n",
       "                    70, 60, 10, 60, 70, 20, 50, 30, 70, 10, 60, 50, 50, 50,\n",
       "                    80, 60, 40, 10, 80, 30, 20, 40, 20, 70, 70, 10, 70, 20,\n",
       "                    50, 60, 40, 50, 60, 40, 40, 90, 50, 60, 50, 60, 40, 50,\n",
       "                    50, 90, 70, 60, 80, 40, 80, 90, 50, 60, 90, 10, 50, 30,\n",
       "                    50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 12, 9, 6, 3, 9, 3, 12, 12, 6, 3, 12, 9, 9, 9, 9, 3,\n",
       "                    3, 12, 6, 3, 12, 3, 12, 3, 3, 6, 3, 12, 3, 9, 12, 12,\n",
       "                    9, 9, 6, 3, 9, 12, 12, 9, 3, 3, 12, 9, 3, 12, 3, 6, 6,\n",
       "                    9, 12, 12, 6, 9, 9, 6, 6, 12, 9, 9, 3, 3, 12, 6, 12, 6,\n",
       "                    9, 12, 6, 9, 12, 3, 6, 9, 6, 12, 12, 12, 12, 9, 6, 6,\n",
       "                    9, 3, 6, 3, 12, 12, 3, 12, 9, 9, 6, 6, 3, 3, 6, 12, 12],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.001, 0.1, 0.1, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.001, 0.1, 0.1, 0.001, 0.1, 0.1, 0.001, 0.01, 0.1,\n",
       "                    0.01, 0.01, 0.1, 0.001, 0.01, 0.01, 0.001, 0.1, 0.1,\n",
       "                    0.1, 0.001, 0.1, 0.01, 0.001, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.01, 0.001, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.1, 0.1, 0.1, 0.001, 0.01, 0.001, 0.01, 0.1, 0.01,\n",
       "                    0.001, 0.1, 0.01, 0.001, 0.1, 0.1, 0.001, 0.1, 0.1,\n",
       "                    0.1, 0.01, 0.001, 0.1, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.001, 0.01, 0.1, 0.01, 0.01, 0.001, 0.1, 0.01, 0.1,\n",
       "                    0.01, 0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.01, 0.1, 0.001, 0.1, 0.001, 0.001,\n",
       "                    0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_colsample_bytree': masked_array(data=[1.0, 0.75, 0.5, 0.5, 0.5, 1.0, 1.0, 0.75, 0.5, 1.0,\n",
       "                    0.5, 0.25, 0.25, 1.0, 0.5, 0.25, 0.25, 0.25, 1.0, 0.25,\n",
       "                    1.0, 0.25, 0.25, 0.25, 0.75, 0.25, 0.25, 0.75, 0.75,\n",
       "                    0.75, 0.75, 0.25, 1.0, 0.75, 0.75, 0.5, 0.5, 0.75, 1.0,\n",
       "                    0.75, 0.5, 0.75, 0.25, 0.25, 0.25, 1.0, 0.5, 0.5, 1.0,\n",
       "                    0.5, 0.75, 0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 0.5, 1.0,\n",
       "                    0.75, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 0.5, 1.0, 1.0,\n",
       "                    0.75, 0.75, 0.75, 0.25, 1.0, 1.0, 0.25, 0.75, 0.5,\n",
       "                    0.25, 0.25, 0.25, 0.25, 1.0, 1.0, 0.25, 0.25, 0.25,\n",
       "                    1.0, 0.75, 0.5, 0.25, 0.25, 0.25, 0.5, 1.0, 0.75, 0.25,\n",
       "                    0.75, 0.5, 0.75],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'subsample': 0.75,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 20,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 70,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 40,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 80,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 9,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 60,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 90,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.5,\n",
       "   'n_estimators': 10,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 0.25},\n",
       "  {'subsample': 0.25,\n",
       "   'n_estimators': 30,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.75},\n",
       "  {'subsample': 1.0,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.001,\n",
       "   'colsample_bytree': 0.5},\n",
       "  {'subsample': 0.75,\n",
       "   'n_estimators': 50,\n",
       "   'max_depth': 12,\n",
       "   'learning_rate': 0.01,\n",
       "   'colsample_bytree': 0.75}],\n",
       " 'split0_test_score': array([-0.01263823,  0.21116377,  0.22222222,  0.08399157,  0.06398104,\n",
       "         0.21300685,  0.03817799,  0.21037388,  0.14744602,  0.18378094,\n",
       "         0.1195366 , -0.03422854,  0.20668773,  0.2164297 ,  0.17272249,\n",
       "        -0.04844655,  0.02711954, -0.07003686,  0.23091101,  0.16692996,\n",
       "        -0.06398104, -0.02448657, -0.04686677, -0.05476567,  0.08662454,\n",
       "         0.14296998,  0.04186414,  0.0674039 ,  0.22248552,  0.17114271,\n",
       "         0.18246445,  0.1195366 ,  0.22748815,  0.23354397,  0.2093207 ,\n",
       "         0.15560821,  0.12769879,  0.22274882,  0.26171669,  0.24117957,\n",
       "         0.20010532,  0.05107952, -0.04844655,  0.01237493, -0.04133755,\n",
       "         0.11400737,  0.24776198,  0.10005266,  0.20853081,  0.14718273,\n",
       "         0.22485519,  0.21563981,  0.24670879,  0.13665087,  0.12269616,\n",
       "         0.22169563,  0.16798315,  0.08320169,  0.2459189 ,  0.19589258,\n",
       "         0.21537651,  0.09136388,  0.12980516,  0.22064244,  0.20563454,\n",
       "         0.21511322,  0.17061611,  0.19220642,  0.2459189 ,  0.17272249,\n",
       "         0.21142707,  0.25592417, -0.06266456,  0.1719326 ,  0.21116377,\n",
       "        -0.03238547,  0.21511322,  0.16877304,  0.13691417, -0.02080042,\n",
       "         0.12164297, -0.04555029,  0.18035808,  0.16587678, -0.05766193,\n",
       "        -0.03475513, -0.06793049,  0.2688257 ,  0.23670353,  0.12480253,\n",
       "         0.19799895,  0.18457083,  0.11348078,  0.1195366 ,  0.164297  ,\n",
       "         0.17087941,  0.08662454,  0.20984729,  0.13954713,  0.24302264]),\n",
       " 'split1_test_score': array([-0.00026392,  0.23172341,  0.18659277, -0.03879652,  0.01319609,\n",
       "         0.19187121,  0.0530483 ,  0.21219319,  0.01900238,  0.17524413,\n",
       "         0.11058327, -0.11163895,  0.16389549,  0.18105041,  0.11718131,\n",
       "        -0.13196094, -0.03826867, -0.15333861,  0.21272103,  0.11929269,\n",
       "        -0.01055688, -0.11929269, -0.14067036, -0.11797308,  0.07442597,\n",
       "         0.12193191, -0.12800211,  0.15149116,  0.21034574,  0.1567696 ,\n",
       "         0.14779625,  0.0567432 ,  0.20453946,  0.19107944,  0.1881763 ,\n",
       "         0.09817894,  0.0760095 ,  0.20612299,  0.25046186,  0.22011085,\n",
       "         0.1290578 ,  0.033782  , -0.14225389, -0.11295856, -0.12430721,\n",
       "         0.09026128,  0.18316178,  0.10345738,  0.19292689, -0.03589338,\n",
       "         0.16996569,  0.20849828,  0.23383478,  0.09976247,  0.09369227,\n",
       "         0.19398258,  0.15861705, -0.04143574,  0.21140143,  0.17471628,\n",
       "         0.185801  ,  0.09448403,  0.12721035,  0.21034574,  0.10583267,\n",
       "         0.19820533,  0.13116917,  0.16574294,  0.2304038 ,  0.08287147,\n",
       "         0.19081552,  0.20823436, -0.14621272,  0.16204803,  0.20190024,\n",
       "        -0.12879388,  0.20031671,  0.01636316,  0.0446028 , -0.11638955,\n",
       "         0.04090789, -0.11955661,  0.15808921,  0.11902877, -0.14014252,\n",
       "        -0.1074162 , -0.14779625,  0.24703088,  0.21562418,  0.09606756,\n",
       "         0.15281077,  0.14568488,  0.05515967,  0.00184745,  0.15281077,\n",
       "         0.14990763,  0.07785695,  0.11797308,  0.07891264,  0.22486144]),\n",
       " 'split2_test_score': array([-0.03562945,  0.15914489,  0.16099235, -0.04433888,  0.0192663 ,\n",
       "         0.1652151 ,  0.00870942,  0.17761942,  0.05225653,  0.1398786 ,\n",
       "         0.09949855, -0.08128794,  0.15228292,  0.17049353,  0.09633149,\n",
       "        -0.09501188, -0.03246239, -0.10477699,  0.14674056,  0.13037741,\n",
       "        -0.09395619, -0.07785695, -0.09738717, -0.07917656,  0.08709422,\n",
       "         0.12430721, -0.10345738,  0.13116917,  0.19213513,  0.13697546,\n",
       "         0.14621272,  0.05489575,  0.17022961,  0.17022961,  0.1652151 ,\n",
       "         0.12536289,  0.10847189,  0.17154922,  0.20638691,  0.18316178,\n",
       "         0.11929269,  0.11955661, -0.09422011, -0.07416205, -0.08524677,\n",
       "         0.08894167,  0.17418844,  0.11163895,  0.18025864, -0.04935339,\n",
       "         0.15281077,  0.18368963,  0.17471628,  0.13116917,  0.0868303 ,\n",
       "         0.15149116,  0.15729744,  0.00263922,  0.17102138,  0.17260491,\n",
       "         0.17656374,  0.07099499,  0.11058327,  0.17893903,  0.15043547,\n",
       "         0.1652151 ,  0.16442333,  0.1543943 ,  0.16891   ,  0.09210874,\n",
       "         0.17418844,  0.19398258, -0.10583267,  0.16415941,  0.15017155,\n",
       "        -0.0807601 ,  0.15835313,  0.05489575,  0.07099499, -0.07416205,\n",
       "         0.07548166, -0.09263658,  0.16838216,  0.13407231, -0.10451306,\n",
       "        -0.09422011, -0.10081816,  0.19873317,  0.16785432,  0.12219583,\n",
       "         0.1314331 ,  0.13591977,  0.08392716,  0.00870942,  0.13222486,\n",
       "         0.12984956,  0.04856163,  0.12773819,  0.09501188,  0.17445236]),\n",
       " 'split3_test_score': array([ 0.00158353,  0.21430457,  0.20005278,  0.03906044,  0.04671417,\n",
       "         0.16732647,  0.02955925,  0.20110847,  0.16415941,  0.17946688,\n",
       "         0.0892056 , -0.05463183,  0.185801  ,  0.1797308 ,  0.14119821,\n",
       "        -0.07944049,  0.00184745, -0.09210874,  0.19002375,  0.11638955,\n",
       "        -0.00501452, -0.06017419, -0.07152283, -0.05806281,  0.06202164,\n",
       "         0.09949855,  0.06070203,  0.03694906,  0.20955397,  0.06624439,\n",
       "         0.14858802,  0.09501188,  0.19239905,  0.21430457,  0.17181314,\n",
       "         0.03853259,  0.09422011,  0.19846925,  0.25204539,  0.19741357,\n",
       "         0.17788335,  0.02639219, -0.06598047, -0.05463183, -0.06228556,\n",
       "         0.07337028,  0.219583  ,  0.09237266,  0.18157825,  0.10213777,\n",
       "         0.17577197,  0.19213513,  0.2074426 ,  0.13644761,  0.10794405,\n",
       "         0.20242808,  0.135128  ,  0.05489575,  0.20137239,  0.18659277,\n",
       "         0.16679863,  0.07284244,  0.06650831,  0.22011085,  0.17471628,\n",
       "         0.20031671,  0.14251781,  0.15069939,  0.20242808,  0.14489311,\n",
       "         0.19530219,  0.21852732, -0.08498285,  0.14647664,  0.17577197,\n",
       "        -0.06439694,  0.20797044,  0.14990763,  0.16838216, -0.06122988,\n",
       "         0.16231196, -0.07442597,  0.14542096,  0.13196094, -0.07416205,\n",
       "        -0.06861969, -0.07468989,  0.253365  ,  0.21483241,  0.09791502,\n",
       "         0.19926102,  0.13275271,  0.15281077,  0.10424914,  0.14937978,\n",
       "         0.03483769,  0.08419108,  0.1797308 ,  0.1229876 ,  0.23462655]),\n",
       " 'split4_test_score': array([-0.0084455 ,  0.18923199,  0.21166535,  0.02084983,  0.03272631,\n",
       "         0.17893903,  0.11691739,  0.19345474,  0.16759039,  0.19160728,\n",
       "         0.11480602, -0.05806281,  0.20981789,  0.20031671,  0.16125627,\n",
       "        -0.0976511 , -0.03219847, -0.11375033,  0.18025864,  0.16838216,\n",
       "        -0.25521246, -0.05384006, -0.08419108, -0.06492478,  0.13803114,\n",
       "         0.14542096,  0.02322513,  0.20321985,  0.18844022,  0.10820797,\n",
       "         0.18131433,  0.08735814,  0.18078649,  0.20058063,  0.17788335,\n",
       "         0.08630245,  0.01214041,  0.21747163,  0.20453946,  0.17761942,\n",
       "         0.17498021,  0.16204803, -0.07917656, -0.05225653, -0.06677224,\n",
       "         0.12615466,  0.19503827,  0.1435735 ,  0.19134336,  0.06914753,\n",
       "         0.19266297,  0.19292689,  0.20585907,  0.09105305,  0.08735814,\n",
       "         0.20321985,  0.14330958,  0.08762206,  0.20084455,  0.18474532,\n",
       "         0.18500924,  0.12272367,  0.12536289,  0.20849828,  0.20797044,\n",
       "         0.19873317,  0.16732647,  0.17471628,  0.19820533,  0.152019  ,\n",
       "         0.19926102,  0.17313275, -0.10820797,  0.16996569,  0.18131433,\n",
       "        -0.06782792,  0.19160728,  0.14911586,  0.17867511, -0.0591185 ,\n",
       "         0.14937978, -0.08023225,  0.17418844,  0.12800211, -0.0976511 ,\n",
       "        -0.06334125, -0.09263658,  0.22169438,  0.16627078,  0.15017155,\n",
       "         0.18474532,  0.16891   ,  0.17682766,  0.14911586,  0.16679863,\n",
       "         0.11005542,  0.07944049,  0.19319082,  0.11718131,  0.20374769]),\n",
       " 'mean_test_score': array([-0.01107903,  0.20111389,  0.19630522,  0.01215397,  0.03517715,\n",
       "         0.18327267,  0.04928136,  0.19895022,  0.11008955,  0.17399531,\n",
       "         0.10672642, -0.06796982,  0.18369691,  0.18960472,  0.1377381 ,\n",
       "        -0.09050147, -0.01479171, -0.10680176,  0.19213199,  0.14027478,\n",
       "        -0.08574214, -0.06712967, -0.08812725, -0.07498071,  0.08963906,\n",
       "         0.12682619, -0.02113483,  0.1180456 ,  0.20459266,  0.12787036,\n",
       "         0.16127542,  0.08270949,  0.19508948,  0.20194803,  0.18248251,\n",
       "         0.10079949,  0.08371011,  0.20327257,  0.23503082,  0.20389835,\n",
       "         0.16026401,  0.07857057, -0.08601532, -0.05632563, -0.07598964,\n",
       "         0.0985473 ,  0.20394739,  0.11021855,  0.19092809,  0.04664468,\n",
       "         0.18321406,  0.1985785 ,  0.21371319,  0.11901716,  0.09970469,\n",
       "         0.19456366,  0.15246783,  0.03738418,  0.20611267,  0.18291051,\n",
       "         0.18591075,  0.09048154,  0.11189493,  0.20770726,  0.16891773,\n",
       "         0.19551692,  0.15521088,  0.16755251,  0.20917425,  0.12892305,\n",
       "         0.19419905,  0.20996163, -0.10157961,  0.16291682,  0.18406509,\n",
       "        -0.07483239,  0.19467235,  0.10781067,  0.11991215, -0.06633945,\n",
       "         0.10994335, -0.08247984,  0.16528826,  0.13578897, -0.09482577,\n",
       "        -0.07367004, -0.09677422,  0.23793042,  0.20025809,  0.1182304 ,\n",
       "         0.17324959,  0.15356832,  0.11643933,  0.07669062,  0.15310223,\n",
       "         0.11910867,  0.07533491,  0.16569608,  0.1107283 ,  0.21614253]),\n",
       " 'std_test_score': array([0.01333715, 0.02495817, 0.02127478, 0.04847317, 0.01846723,\n",
       "        0.01764812, 0.0367337 , 0.01261556, 0.06207551, 0.01789634,\n",
       "        0.01098607, 0.02645387, 0.02277841, 0.0165548 , 0.02802216,\n",
       "        0.02713496, 0.02529823, 0.02751646, 0.02875319, 0.02284391,\n",
       "        0.09102581, 0.03124011, 0.03111391, 0.02307373, 0.02588934,\n",
       "        0.01663391, 0.07852605, 0.05947435, 0.0126014 , 0.03734929,\n",
       "        0.01685285, 0.0244017 , 0.01984399, 0.02134087, 0.01540088,\n",
       "        0.0392469 , 0.0395979 , 0.01799194, 0.02445385, 0.02372968,\n",
       "        0.03087719, 0.05316413, 0.03190567, 0.04065764, 0.02790689,\n",
       "        0.01895212, 0.02668864, 0.01778769, 0.01015195, 0.07710135,\n",
       "        0.02440793, 0.01170179, 0.024962  , 0.01957109, 0.01379042,\n",
       "        0.02336069, 0.0117167 , 0.04969849, 0.02405963, 0.0084715 ,\n",
       "        0.01625895, 0.0186929 , 0.02365697, 0.01520782, 0.03802183,\n",
       "        0.01638831, 0.01554421, 0.01496411, 0.02678835, 0.03516567,\n",
       "        0.01212895, 0.02757079, 0.02772781, 0.0089837 , 0.02134315,\n",
       "        0.03132708, 0.01977405, 0.06059321, 0.05320833, 0.03071981,\n",
       "        0.04558046, 0.02413185, 0.01234838, 0.01590294, 0.02815577,\n",
       "        0.02532927, 0.02813007, 0.024802  , 0.0282206 , 0.01991465,\n",
       "        0.0267869 , 0.02001748, 0.04425006, 0.06010583, 0.01235093,\n",
       "        0.04674932, 0.01375452, 0.03638892, 0.02136259, 0.02462519]),\n",
       " 'rank_test_score': array([ 81,  14,  18,  80,  79,  30,  76,  16,  62,  34,  65,  87,  29,\n",
       "         26,  48,  96,  82, 100,  24,  47,  93,  86,  95,  90,  70,  52,\n",
       "         83,  57,   9,  51,  41,  72,  20,  13,  33,  66,  71,  12,   2,\n",
       "         11,  42,  73,  94,  84,  91,  68,  10,  61,  25,  77,  31,  17,\n",
       "          4,  55,  67,  22,  46,  78,   8,  32,  27,  69,  59,   7,  36,\n",
       "         19,  43,  37,   6,  50,  23,   5,  99,  40,  28,  89,  21,  64,\n",
       "         53,  85,  63,  92,  39,  49,  97,  88,  98,   1,  15,  56,  35,\n",
       "         44,  58,  74,  45,  54,  75,  38,  60,   3], dtype=int32)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.760\n",
      "ROC AUC Teste: 0.715\n",
      "Lucro Relativo: -0.337\n",
      "Lucro Relativo Teste: -0.243\n",
      "Lucro Total: -63960.00\n",
      "Lucro Total Teste: -45972.44\n",
      "F1: 0.296\n",
      "F1 Teste: 0.256\n"
     ]
    }
   ],
   "source": [
    "\n",
    "XGB = XGBClassifier(\n",
    "   scale_pos_weight = sum(y_train == 0) / sum(y_train == 1),\n",
    "   n_estimators = 10,\n",
    "   max_depth = 12,\n",
    "   learning_rate = 0.01,\n",
    "   subsample = 0.25,\n",
    "   colsample_bytree = 1,\n",
    "   random_state = 42\n",
    ")\n",
    "XGB.fit(x_train,y_train)\n",
    "y_p_train = XGB.predict(x_train)\n",
    "y_p_test = XGB.predict(x_test)\n",
    "\n",
    "auc = roc_auc_score(y_train, y_p_train)\n",
    "auc_test = roc_auc_score(y_test, y_p_test)\n",
    "print('ROC AUC: %.3f' % auc)\n",
    "print('ROC AUC Teste: %.3f' % auc_test)\n",
    "\n",
    "LR = funcao_lucro(y_train, y_p_train)\n",
    "LR_test = funcao_lucro(y_test, y_p_test)\n",
    "print('Lucro Relativo: %.3f' % (-1*LR))\n",
    "print('Lucro Relativo Teste: %.3f' % (-1*LR_test))\n",
    "print('Lucro Total: %.2f' % ((-1*LR)*LM))\n",
    "print('Lucro Total Teste: %.2f' % ((-1*LR_test)*LM))\n",
    "\n",
    "F1 = f1_score(y_train, y_p_train)\n",
    "F1_test = f1_score(y_test, y_p_test)\n",
    "print('F1: %.3f' % F1)\n",
    "print('F1 Teste: %.3f' % F1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SELECTION - RANDOM FOREST - GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 232), (53214,))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separa X e Y de treino\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_train = train_set[features_3.columns]\n",
    "y_train = train_set['TARGET']\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao que verifica se o lucro do modelo se aproxima do lucro max que poderia ter\n",
    "\n",
    "def funcao_lucro(y_true, y_pred):\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred).ravel().tolist()\n",
    "    fp = cm[1]\n",
    "    tp = cm[3]\n",
    "\n",
    "    lucro_max = sum(y_true)*90\n",
    "    \n",
    "    f_lucro = ((-10*fp)+(90*tp))/lucro_max\n",
    "\n",
    "    return f_lucro\n",
    "\n",
    "lucro = make_scorer(funcao_lucro, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Lucro Relativo: 0.042\n"
     ]
    }
   ],
   "source": [
    "#Como os dados nao sao balanceados\n",
    "#Another approach to make random forest more suitable for learning from extremely imbalanced data follows the idea of cost\n",
    "# sensitive learning. Since the RF classifier tends to be biased towards the majority class, we shall place a heavier penalty\n",
    "# on misclassifying the minority class.\n",
    "#class weight = balanced -> This argument takes a dictionary with a mapping of each class value (e.g. 0 and 1) to the weighting. The argument value of\n",
    "# ‘balanced‘ can be provided to automatically use the inverse weighting from the training dataset, giving focus to the\n",
    "# minority class.\n",
    "#class_weight='balanced_subsample' -> Given that each decision tree is constructed from a bootstrap sample (e.g. random selection with replacement), the class\n",
    "# distribution in the data sample will be different for each tree.\n",
    "#As such, it might be interesting to change the class weighting based on the class distribution in each bootstrap sample,\n",
    "# instead of the entire training dataset.\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 10, class_weight='balanced_subsample',random_state=42)\n",
    "\n",
    "scores = cross_val_score(rnd_clf, x_train, y_train, scoring=lucro, cv=10) #para classificacao o cv ja eh estratificado pela target\n",
    "\n",
    "print('Media Lucro Relativo: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'class_weight': ['balanced_subsample'],\n",
       "                         'criterion': ['gini'], 'max_depth': range(5, 20, 5),\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [30, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(funcao_lucro), verbose=0)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Faz Grid Search para ver se teriamos algum valor melhor para os hiperparametros\n",
    "#Foi testado 'n_estimators': [10,30,50] E 'max_depth': range(5,50,10) E 'max_features': ['sqrt','log2'] -> best = 50, 5, sqrt\n",
    "#Foi testado 'n_estimators': [30,50,100] E 'max_depth': range(5,20,10) E 'max_features': ['sqrt','log2'] -> best = 100, 5, sqrt\n",
    "\n",
    "grid_param = {\n",
    "    'n_estimators': [30,50,100],\n",
    "    'criterion': ['gini'], #default\n",
    "    'max_depth': range(5,20,5),\n",
    "    'max_features': ['sqrt','log2'],\n",
    "    'class_weight':['balanced_subsample']\n",
    "}\n",
    "\n",
    "rnd_clf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(rnd_clf,grid_param,scoring=lucro,cv=10)\n",
    "\n",
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "                       criterion='gini', max_depth=15, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced_subsample',\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 15,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0650460954889537 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 30}\n",
      "-0.06884840261326725 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}\n",
      "-0.0652041453283581 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "-0.0821851848638086 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 30}\n",
      "-0.08082422667351766 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 50}\n",
      "-0.08197727486340735 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.08388962934144628 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 30}\n",
      "0.05876853905622482 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.06745320481252497 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "-0.03639264855414901 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 30}\n",
      "-0.04351662157211494 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 50}\n",
      "-0.04399507753635244 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.17803943244886608 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 30}\n",
      "0.1802444660761976 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.1815416570763799 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.021322968077581526 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'log2', 'n_estimators': 30}\n",
      "-0.005688938753715027 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'log2', 'n_estimators': 50}\n",
      "0.010322518087240587 {'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'log2', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'],cvres['params']):\n",
    "    print(mean_score,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Lucro Relativo: 0.184\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(criterion = 'gini',\n",
    " max_depth = 15,\n",
    " max_features = 'sqrt',\n",
    " n_estimators = 100,\n",
    " class_weight = 'balanced_subsample', random_state=42)\n",
    "\n",
    "scores = cross_val_score(rnd_clf, x_train, y_train, scoring=lucro, cv=10) #para classificacao o cv ja eh estratificado pela target\n",
    "\n",
    "print('Media Lucro Relativo: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var15                        0.168336\n",
       "saldo_var30                  0.044406\n",
       "var38                        0.044155\n",
       "saldo_medio_var5_hace2       0.040667\n",
       "saldo_medio_var5_hace3       0.038507\n",
       "                               ...   \n",
       "delta_imp_amort_var18_1y3    0.000000\n",
       "imp_amort_var18_ult1         0.000000\n",
       "imp_var7_emit_ult1           0.000000\n",
       "imp_aport_var33_ult1         0.000000\n",
       "delta_num_aport_var17_1y3    0.000000\n",
       "Length: 232, dtype: float64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.fit(x_train,y_train)\n",
    "\n",
    "feature_scores = pd.Series(rnd_clf.feature_importances_, index=x_train.columns).sort_values(ascending=False)\n",
    "\n",
    "feature_scores.to_csv('feature_importance.csv',header=False)\n",
    "\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature_scores <= 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff227034910>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x640 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "feat_importance = pd.Series(rnd_clf.feature_importances_, index= x_train.columns)\n",
    "\n",
    "feat_importance.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_4 = []\n",
    "to_drop_4 = feature_scores.loc[lambda x: x <= 0].index[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var17_ult1</th>\n",
       "      <th>saldo_medio_var17_ult3</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>61553</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>48.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>209.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175887.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6865</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111297.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40817</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80805.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71630</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124585.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "61553     2     38                48.0                    102.0   \n",
       "6865      2     51                 0.0                      0.0   \n",
       "847       2     23                 0.0                      0.0   \n",
       "40817     2     23                 0.0                      0.0   \n",
       "71630     2     23                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "61553                    209.7                      0.0   \n",
       "6865                       0.0                      0.0   \n",
       "847                        0.0                      0.0   \n",
       "40817                      0.0                      0.0   \n",
       "71630                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "61553                      0.0                      0.0   \n",
       "6865                       0.0                      0.0   \n",
       "847                        0.0                      0.0   \n",
       "40817                      0.0                      0.0   \n",
       "71630                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "61553                      0.0                0.0  ...   \n",
       "6865                       0.0                0.0  ...   \n",
       "847                        0.0                0.0  ...   \n",
       "40817                      0.0                0.0  ...   \n",
       "71630                      0.0                0.0  ...   \n",
       "\n",
       "       saldo_medio_var17_ult1  saldo_medio_var17_ult3  \\\n",
       "61553                     0.0                     0.0   \n",
       "6865                      0.0                     0.0   \n",
       "847                       0.0                     0.0   \n",
       "40817                     0.0                     0.0   \n",
       "71630                     0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "61553                      0.0                     0.0   \n",
       "6865                       0.0                     0.0   \n",
       "847                        0.0                     0.0   \n",
       "40817                      0.0                     0.0   \n",
       "71630                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "61553                     0.0                      0.0   \n",
       "6865                      0.0                      0.0   \n",
       "847                       0.0                      0.0   \n",
       "40817                     0.0                      0.0   \n",
       "71630                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "61553                      0.0                     0.0   \n",
       "6865                       0.0                     0.0   \n",
       "847                        0.0                     0.0   \n",
       "40817                      0.0                     0.0   \n",
       "71630                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  \n",
       "61553                     0.0  175887.150000  \n",
       "6865                      0.0  111297.030000  \n",
       "847                       0.0  117310.979016  \n",
       "40817                     0.0   80805.900000  \n",
       "71630                     0.0  124585.620000  \n",
       "\n",
       "[5 rows x 212 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_4 = features_3.drop(to_drop_4, axis=1)\n",
    "features_4.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 212), (53214,))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separa X e Y de treino\n",
    "x_train = train_set[features_4.columns]\n",
    "y_train = train_set['TARGET']\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22806, 212), (22806,))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separa X e Y de treino\n",
    "x_test = test_set[features_4.columns]\n",
    "y_test = test_set['TARGET']\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Funcao de Lucro para Maximizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao que verifica se o lucro do modelo se aproxima do lucro max que poderia ter\n",
    "\n",
    "def funcao_lucro(y_true, y_pred):\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred).ravel().tolist()\n",
    "    fp = cm[1]\n",
    "    tp = cm[3]\n",
    "\n",
    "    lucro_max = sum(y_true)*90\n",
    "    \n",
    "    f_lucro = ((-10*fp)+(90*tp))/lucro_max\n",
    "\n",
    "    return f_lucro\n",
    "\n",
    "lucro = make_scorer(funcao_lucro, greater_is_better=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lucro Maximo (100% acerto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucro Maximo: 189540.00\n"
     ]
    }
   ],
   "source": [
    "LM = sum(y_train)*90\n",
    "print('Lucro Maximo: %.2f' % LM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acao para todos os clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.500\n",
      "Lucro Relativo: -1.696\n",
      "Lucro Total: -321540.00\n",
      "F1: 0.076\n"
     ]
    }
   ],
   "source": [
    "y_acao = pd.Series(np.ones(len(y_train)),name='TARGET',dtype=int)\n",
    "\n",
    "auc = roc_auc_score(y_train, y_acao.to_list())\n",
    "print('ROC AUC: %.3f' % auc)\n",
    "LR = funcao_lucro(y_train,y_acao.to_list())\n",
    "print('Lucro Relativo: %.3f' % LR)\n",
    "print('Lucro Total: %.2f' % (LR*LM))\n",
    "F1 = f1_score(y_train, y_acao.to_list())\n",
    "print('F1: %.3f' % F1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.890\n",
      "ROC AUC Teste: 0.733\n",
      "Lucro Relativo: 0.542\n",
      "Lucro Relativo Teste: 0.208\n",
      "Lucro Total: 102710.00\n",
      "Lucro Total Teste: 39364.92\n",
      "F1: 0.345\n",
      "F1 Teste: 0.233\n"
     ]
    }
   ],
   "source": [
    "#Treinando e Testando o modelo base\n",
    "XGB = XGBClassifier(\n",
    "   scale_pos_weight = sum(y_train == 0) / sum(y_train == 1),\n",
    "   # max_depth = 6,\n",
    "   # learning_rate = 0.3,\n",
    "   random_state = 42\n",
    ")\n",
    "XGB.fit(x_train,y_train)\n",
    "y_p_train = XGB.predict(x_train)\n",
    "y_p_test = XGB.predict(x_test)\n",
    "\n",
    "auc = roc_auc_score(y_train, y_p_train)\n",
    "auc_test = roc_auc_score(y_test, y_p_test)\n",
    "print('ROC AUC: %.3f' % auc)\n",
    "print('ROC AUC Teste: %.3f' % auc_test)\n",
    "\n",
    "LR = funcao_lucro(y_train, y_p_train)\n",
    "LR_test = funcao_lucro(y_test, y_p_test)\n",
    "print('Lucro Relativo: %.3f' % LR)\n",
    "print('Lucro Relativo Teste: %.3f' % LR_test)\n",
    "print('Lucro Total: %.2f' % (LR*LM))\n",
    "print('Lucro Total Teste: %.2f' % (LR_test*LM))\n",
    "\n",
    "F1 = f1_score(y_train, y_p_train)\n",
    "F1_test = f1_score(y_test, y_p_test)\n",
    "print('F1: %.3f' % F1)\n",
    "print('F1 Teste: %.3f' % F1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuna hiperparametros\n",
    "#Faz grid search para selecionar os melhores hiperparametros\n",
    "#Feature selection\n",
    "#grafico de aumento de vars por aumento de lucro (menor complexidade vs maior lucro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz Random Search para ver se teriamos algum valor melhor para os hiperparametros\n",
    "#Random Search eh melhor para tunar hiperparametros com XGBoost, pois ele considera algumas combinacoes aleatorias de parametros e nao\n",
    "# todas (como o Grid Search). Logo, como o XGBoost faz modelos sequenciais e, consequentemente, demora mais, melhor usar o Random. \n",
    "#https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "\n",
    "#Fiz 'learning_rate': np.arange(0.1,1.01,0.2) -> 0.1\n",
    "\n",
    "XGB_grid_param = {\n",
    "    'n_estimators': range(10,100,10),\n",
    "    'max_depth': range(3,13,3), #default 6\n",
    "    'learning_rate': [0.01,0.1,0.3], #default 0,3\n",
    "    'subsample': np.arange(0.25,1.01,0.25), #default 1\n",
    "    'colsample_bytree': np.arange(0.25,1.01,0.25), #default 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           callbacks=None, colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=0, gpu_id=-1,\n",
       "                                           grow_policy='depthwise',\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints='',\n",
       "                                           learni...\n",
       "                   iid='warn', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': array([0.25, 0.5 , 0.75, 1.  ]),\n",
       "                                        'learning_rate': [0.001, 0.01, 0.1,\n",
       "                                                          0.3],\n",
       "                                        'max_depth': range(3, 13, 3),\n",
       "                                        'n_estimators': range(10, 100, 10),\n",
       "                                        'subsample': array([0.25, 0.5 , 0.75, 1.  ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=make_scorer(funcao_lucro),\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(estimator=XGB, \n",
    "                           param_distributions=XGB_grid_param,\n",
    "                           n_iter=100,\n",
    "                           scoring=lucro, \n",
    "                           n_jobs=-1, \n",
    "                           cv=5)\n",
    "\n",
    "random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1.0,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=12, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=20, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='binary:logistic',\n",
       "              predictor='auto', random_state=42, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.25,\n",
       " 'n_estimators': 20,\n",
       " 'max_depth': 12,\n",
       " 'learning_rate': 0.01,\n",
       " 'colsample_bytree': 1.0}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21687569626742753 {'subsample': 0.75, 'n_estimators': 80, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.21967869822205585 {'subsample': 0.75, 'n_estimators': 80, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.13358557768037752 {'subsample': 0.5, 'n_estimators': 70, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.12173175633640014 {'subsample': 0.5, 'n_estimators': 10, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.11674562630172344 {'subsample': 1.0, 'n_estimators': 10, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.17118815704121002 {'subsample': 0.5, 'n_estimators': 80, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 0.5}\n",
      "0.1978323502463499 {'subsample': 1.0, 'n_estimators': 30, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 0.25}\n",
      "0.21054641021833587 {'subsample': 1.0, 'n_estimators': 30, 'max_depth': 12, 'learning_rate': 0.3, 'colsample_bytree': 0.75}\n",
      "0.17287922475827638 {'subsample': 0.75, 'n_estimators': 40, 'max_depth': 6, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
      "0.15466668307510514 {'subsample': 0.5, 'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.001, 'colsample_bytree': 0.75}\n",
      "0.15884349709621018 {'subsample': 0.25, 'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 0.25}\n",
      "0.2125584637936938 {'subsample': 0.75, 'n_estimators': 30, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.20801498797981163 {'subsample': 1.0, 'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.18605508134575582 {'subsample': 0.25, 'n_estimators': 30, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 0.5}\n",
      "0.1181722695714168 {'subsample': 0.5, 'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.11801349244003158 {'subsample': 0.25, 'n_estimators': 60, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.12299945497546394 {'subsample': 0.5, 'n_estimators': 10, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "-0.03193766211715293 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 0.25}\n",
      "0.2036407791549178 {'subsample': 0.25, 'n_estimators': 90, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.1982571251803454 {'subsample': 0.75, 'n_estimators': 30, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 0.25}\n",
      "0.14298392631655343 {'subsample': 0.5, 'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.3, 'colsample_bytree': 0.5}\n",
      "0.20384881030175606 {'subsample': 1.0, 'n_estimators': 10, 'max_depth': 12, 'learning_rate': 0.3, 'colsample_bytree': 0.5}\n",
      "0.19504985021333532 {'subsample': 0.25, 'n_estimators': 10, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.14865229123342513 {'subsample': 0.25, 'n_estimators': 10, 'max_depth': 3, 'learning_rate': 0.001, 'colsample_bytree': 0.5}\n",
      "0.09965466216792918 {'subsample': 0.75, 'n_estimators': 10, 'max_depth': 3, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
      "0.19398356922757987 {'subsample': 1.0, 'n_estimators': 30, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 0.75}\n",
      "0.20854775731119365 {'subsample': 0.75, 'n_estimators': 30, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.15548409546528694 {'subsample': 1.0, 'n_estimators': 10, 'max_depth': 6, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
      "0.20336322129535048 {'subsample': 0.5, 'n_estimators': 90, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.20554028694168996 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.1690832010183442 {'subsample': 1.0, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.12361092206155874 {'subsample': 0.25, 'n_estimators': 70, 'max_depth': 3, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
      "0.17625699839549916 {'subsample': 0.75, 'n_estimators': 40, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.05338967246998102 {'subsample': 0.5, 'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "-0.014384570623847895 {'subsample': 1.0, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.001, 'colsample_bytree': 0.75}\n",
      "0.20690457033202594 {'subsample': 0.25, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.16770662354545435 {'subsample': 0.25, 'n_estimators': 30, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 0.75}\n",
      "0.1858113797704452 {'subsample': 0.25, 'n_estimators': 70, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.21250357218053276 {'subsample': 0.75, 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.10711149789248721 {'subsample': 0.5, 'n_estimators': 10, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.18528517327852748 {'subsample': 1.0, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.13136635097458838 {'subsample': 0.75, 'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
      "0.20669062274331246 {'subsample': 0.5, 'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.0511167511148284 {'subsample': 0.5, 'n_estimators': 70, 'max_depth': 3, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.20848539578646055 {'subsample': 1.0, 'n_estimators': 40, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.0493658535420738 {'subsample': 1.0, 'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.10614683201806396 {'subsample': 0.25, 'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.3, 'colsample_bytree': 0.5}\n",
      "0.09956895414909359 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.001, 'colsample_bytree': 0.75}\n",
      "0.1500763305315651 {'subsample': 0.75, 'n_estimators': 10, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.11385805095582405 {'subsample': 0.25, 'n_estimators': 10, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.17515172729480197 {'subsample': 1.0, 'n_estimators': 40, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.1905025785412615 {'subsample': 1.0, 'n_estimators': 40, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
      "0.2101848724780111 {'subsample': 0.75, 'n_estimators': 90, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.11467435509146295 {'subsample': 0.75, 'n_estimators': 20, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.2125477413739908 {'subsample': 0.5, 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.16823971139806296 {'subsample': 1.0, 'n_estimators': 30, 'max_depth': 6, 'learning_rate': 0.3, 'colsample_bytree': 0.5}\n",
      "0.01607549122082297 {'subsample': 0.75, 'n_estimators': 40, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "-0.016894378948862174 {'subsample': 1.0, 'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 0.25}\n",
      "0.12678016304143555 {'subsample': 0.25, 'n_estimators': 40, 'max_depth': 6, 'learning_rate': 0.3, 'colsample_bytree': 0.5}\n",
      "0.1768931352338302 {'subsample': 0.75, 'n_estimators': 70, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.2106994720667756 {'subsample': 0.75, 'n_estimators': 80, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.21428955602638206 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.16543111815129946 {'subsample': 0.5, 'n_estimators': 80, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 0.75}\n",
      "0.18417239698470253 {'subsample': 0.5, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.3, 'colsample_bytree': 0.5}\n",
      "0.124678803410218 {'subsample': 0.25, 'n_estimators': 10, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.21766380491631476 {'subsample': 0.25, 'n_estimators': 50, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.216401633681799 {'subsample': 0.75, 'n_estimators': 90, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.18601217025355457 {'subsample': 0.75, 'n_estimators': 10, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 0.5}\n",
      "0.16644752953954867 {'subsample': 0.75, 'n_estimators': 30, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.17439823537580074 {'subsample': 0.5, 'n_estimators': 40, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 0.25}\n",
      "0.18945091613080117 {'subsample': 0.75, 'n_estimators': 90, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.04059835961818422 {'subsample': 0.75, 'n_estimators': 70, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.18395754617876142 {'subsample': 0.75, 'n_estimators': 70, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.22220683654927906 {'subsample': 0.25, 'n_estimators': 10, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "0.11844985664815516 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.20590502482018821 {'subsample': 0.75, 'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "-0.01151358513083677 {'subsample': 0.75, 'n_estimators': 40, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.11015627706154525 {'subsample': 0.75, 'n_estimators': 10, 'max_depth': 3, 'learning_rate': 0.3, 'colsample_bytree': 0.75}\n",
      "-0.0209791514065212 {'subsample': 0.5, 'n_estimators': 20, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 0.25}\n",
      "0.1298694535950826 {'subsample': 0.25, 'n_estimators': 30, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.17515185128561225 {'subsample': 0.75, 'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.3, 'colsample_bytree': 0.75}\n",
      "0.2121331499051412 {'subsample': 0.75, 'n_estimators': 60, 'max_depth': 12, 'learning_rate': 0.1, 'colsample_bytree': 0.75}\n",
      "0.16431567794723556 {'subsample': 0.5, 'n_estimators': 10, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.211132605274179 {'subsample': 0.75, 'n_estimators': 40, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.24062507233468144 {'subsample': 0.25, 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "0.1253085570370984 {'subsample': 1.0, 'n_estimators': 20, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.18749802725625958 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.21211543590808202 {'subsample': 0.75, 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.1482996831349663 {'subsample': 0.5, 'n_estimators': 10, 'max_depth': 6, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
      "0.2110245441920666 {'subsample': 0.25, 'n_estimators': 70, 'max_depth': 6, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.19430139352000503 {'subsample': 1.0, 'n_estimators': 90, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "-0.0384379339616805 {'subsample': 0.25, 'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.25}\n",
      "0.22031092513064984 {'subsample': 1.0, 'n_estimators': 70, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "0.20274285423116273 {'subsample': 1.0, 'n_estimators': 40, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "0.22912065504909856 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.21556025855731129 {'subsample': 0.5, 'n_estimators': 20, 'max_depth': 9, 'learning_rate': 0.001, 'colsample_bytree': 1.0}\n",
      "0.16898744892118825 {'subsample': 1.0, 'n_estimators': 20, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "0.23798348058263594 {'subsample': 0.5, 'n_estimators': 50, 'max_depth': 12, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "0.20084453732029797 {'subsample': 0.25, 'n_estimators': 40, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.1365345110363819 {'subsample': 0.75, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.3, 'colsample_bytree': 0.5}\n"
     ]
    }
   ],
   "source": [
    "cvres = random_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'],cvres['params']):\n",
    "    print(mean_score,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.761\n",
      "ROC AUC Teste: 0.715\n",
      "Lucro Relativo: 0.346\n",
      "Lucro Relativo Teste: 0.253\n",
      "Lucro Total: 65620.00\n",
      "Lucro Total Teste: 47863.64\n",
      "F1: 0.303\n",
      "F1 Teste: 0.262\n"
     ]
    }
   ],
   "source": [
    "\n",
    "XGB = XGBClassifier(\n",
    "   scale_pos_weight = sum(y_train == 0) / sum(y_train == 1),\n",
    "   n_estimators = 20, #30 40 60\n",
    "   max_depth = 12, #6 9 12\n",
    "   learning_rate = 0.01, #0.01 0.1 0.01\n",
    "   colsample_bytree = 1,\n",
    "   subsample = 0.25,\n",
    "   random_state = 42\n",
    ")\n",
    "XGB.fit(x_train,y_train)\n",
    "y_p_train = XGB.predict(x_train)\n",
    "y_p_test = XGB.predict(x_test)\n",
    "\n",
    "auc = roc_auc_score(y_train, y_p_train)\n",
    "auc_test = roc_auc_score(y_test, y_p_test)\n",
    "print('ROC AUC: %.3f' % auc)\n",
    "print('ROC AUC Teste: %.3f' % auc_test)\n",
    "\n",
    "LR = funcao_lucro(y_train, y_p_train)\n",
    "LR_test = funcao_lucro(y_test, y_p_test)\n",
    "print('Lucro Relativo: %.3f' % LR)\n",
    "print('Lucro Relativo Teste: %.3f' % LR_test)\n",
    "print('Lucro Total: %.2f' % (LR*LM))\n",
    "print('Lucro Total Teste: %.2f' % (LR_test*LM))\n",
    "\n",
    "F1 = f1_score(y_train, y_p_train)\n",
    "F1_test = f1_score(y_test, y_p_test)\n",
    "print('F1: %.3f' % F1)\n",
    "print('F1 Teste: %.3f' % F1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Lucro Relativo: 0.240\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(XGB, x_train, y_train, scoring=lucro, cv=10) #para classificacao o cv ja eh estratificado pela target\n",
    "\n",
    "print('Media Lucro Relativo: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC AUC: 0.768\n",
    "ROC AUC Teste: 0.759\n",
    "Lucro Relativo: 0.208\n",
    "Lucro Relativo Teste: 0.180\n",
    "Lucro Total: 39400.00\n",
    "Lucro Total Teste: 34181.64\n",
    "F1: 0.227\n",
    "F1 Teste: 0.219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "saldo_var30                0.084554\n",
       "var15                      0.030287\n",
       "imp_op_var39_ult1          0.020765\n",
       "num_sal_var16_ult1         0.020743\n",
       "num_op_var41_comer_ult1    0.020204\n",
       "                             ...   \n",
       "saldo_var20                0.000000\n",
       "saldo_var24                0.000000\n",
       "num_op_var40_efect_ult1    0.000000\n",
       "num_op_var40_comer_ult3    0.000000\n",
       "saldo_var31                0.000000\n",
       "Length: 212, dtype: float32"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB.fit(x_train,y_train)\n",
    "\n",
    "feature_scores = pd.Series(XGB.feature_importances_, index=x_train.columns).sort_values(ascending=False)\n",
    "\n",
    "feature_scores.to_csv('feature_importance_XGB.csv',header=False)\n",
    "\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature_scores <= 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff226d52590>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x640 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "feat_importance = pd.Series(XGB.feature_importances_, index= x_train.columns)\n",
    "\n",
    "feat_importance.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
